\documentclass[oneside,letterpaper,titlepage]{article}
%\usepackage[ae,hyper]{/usr/lib/R/share/texmf/Rd}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage[reqno]{amsmath}
\usepackage{amssymb}
\usepackage{verbatim}
\usepackage{epsf}
\usepackage{url}
\usepackage{html}
\usepackage{dcolumn}
\usepackage{fullpage}
\newcolumntype{.}{D{.}{.}{-1}}
\newcolumntype{d}[1]{D{.}{.}{#1}}
%\pagestyle{myheadings}
\htmladdtonavigation{
  \htmladdnormallink{%
    \htmladdimg{http://gking.harvard.edu/pics/home.gif}}
  {http://gking.harvard.edu/}}
\newcommand{\hlink}{\htmladdnormallink}

\bodytext{ BACKGROUND="http://gking.harvard.edu/pics/temple.jpg"}
\setcounter{tocdepth}{3}

\newcommand{\MatchIt}{\textsc{MatchIt}}

\title{\MatchIt: Nonparametric Preprocessing for Parametric Causal
  Inference}

\author{Daniel E. Ho,\thanks{Institute for Quantitative Social
    Science, 34 Kirkland, Cambridge MA 02138,
    USA; \texttt{http://people.iq.harvard.edu/~dho/}, \texttt{daniel.e.ho@gmail.com}.}
\and
Kosuke Imai,\thanks{Assistant Professor, Department of Politics,
  Princeton University (Corwin Hall 041, Department of Politics,
  Princeton University, Princeton NJ 08544, USA;
  \texttt{http://imai.princeton.edu},
  \texttt{kimai@Princeton.Edu}).}
\and
Gary King,\thanks{David Florence Professor of Government, Harvard
  University (Institute for Quantitative Social Science, 34
  Kirkland Street, Harvard University, Cambridge MA 02138;
  \texttt{http://GKing.Harvard.Edu}, \texttt{King@Harvard.Edu}, (617)
  495-2027).}
\and
Elizabeth A. Stuart\thanks{Researcher, Mathematica Policy Research,
  Inc.\, Ph.D.\, Department of Statistics, Harvard University. (600
  Maryland Ave., SW, Suite 550, Washington, DC 20024, USA;
  \texttt{http://www.mathematica-mpr.com},
  \texttt{EStuart@Mathematica-MPR.com}).}}

\makeindex

\begin{document}
\maketitle

\SweaveOpts{strip.white=true}

\begin{rawhtml}
  <p> [Also available is a downloadable <a
  href="/matchit/docs/matchit.pdf">PDF</a> version of this entire
  document]
\end{rawhtml}

\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\section{Introduction}
\label{sec:intro}

\MatchIt\ implements the suggestions of \citet*{HoImaKin05} for
improving parametric statistical models and reducing model dependence
by preprocessing data with semi-parametric and non-parametric matching
methods.  After preprocessing with \MatchIt, researchers can use
whatever parametric model they would have used without \MatchIt, but
produce inferences that are substantially more robust and less
sensitive to modeling assumptions.  Matched data sets created by
\MatchIt\ can also be entered easily into
\hlink{Zelig}{http://gking.harvard.edu/zelig/} \citep{ImaKinLau04}, or
other programs, for subsequent parametric analyses.  \MatchIt\ reduces
the dependence of causal inferences on commonly made, but
hard-to-justify, statistical modeling assumptions via a wide range of
sophisticated matching methods.  In addition, we have written
\MatchIt\ so that adding new matching methods to the software is easy,
if you have the inclination.

\subsection{Software Requirements} 
\label{subsec:require}

\MatchIt\ works in conjunction with the R programming language and
statistical software, and will run on any platform where R is
installed (Windows, Unix, or Mac OS X).  R is available free for
download at the Comprehensive R Archive Network (CRAN) at
\hlink{http://cran.r-project.org/}{http://cran.r-project.org/}.
\MatchIt\ has been tested on the most recent version of R.  A good way
to learn R, if you don't know it already, is to learn Zelig (available
at \hlink{http://gking.harvard.edu}{http://gking.harvard.edu}) which
includes a self-contained introduction to R and can be used to analyze
the matched data after running \MatchIt.

\subsection{Installing \MatchIt}
\label{subsec:install}

To install \MatchIt\ for all platforms, type at the R command prompt:
<<results=hide, eval=FALSE>>=
install.packages("MatchIt")
@
and \MatchIt\ will install itself onto your system automatically.
During the installation process you may either decide to keep or
discard the installation files, which will not affect the way
\MatchIt\ runs.  Note that you only need to do this once.  Some users
may also find it helpful to install the package with version control
(see Subsection~\ref{subsec:vercontrol}).

\subsection{Loading \MatchIt} \label{subsec:load}

As with any R package, you need install \MatchIt\ only once, but you
must load it prior to each use.  You can do this for each R session by
typing
<<results=hide>>=
library(MatchIt) 
@
at the R command prompt.  

Alternatively, you can specify R to load \MatchIt\ automatically at
launch so that you can skip the step of typing {\tt library(MatchIt)}
at the beginning of every R session.  To do this, edit the {\tt
  Rprofile} file located in the R program subdirectory, e.g.
\texttt{C:/R/rw2011/etc/}, for Windows systems or the {\tt .Rprofile}
file located in the home directory for Unix/Linux and Mac OS X
systems.  Using a text editor such as Windows notepad and emacs, add
the following line to the file:
<<results=hide, eval=FALSE>>=
options(defaultPackages = c(getOption("defaultPackages"), "MatchIt"))
@
For this change to take effect, you need to restart R.

\subsection{Updating \MatchIt}

We recommend that you periodically update \MatchIt\ at the R prompt by typing:
<<results=hide, eval=FALSE>>=
update.packages()
library(MatchIt) 
@
which will update all the libraries including \MatchIt and load the
new version of \MatchIt.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Statistical Overview}

\MatchIt\ is designed for studies with a dependent variable (or a set
of dependent variables) that is a function of a dichotomous causal (or
``treatment'') variable, with values known as the ``treated'' and
``control'' groups, and a set of ``pretreatment'' covariates, i.e.,
that are causally prior to the administration of the treatment.
\MatchIt\ works for experimental data, but is also designed for
observational studies where the treatment variable is simply observed
rather than manipulated by the investigator.  \MatchIt\ can be used
for other types of causal variables by dichotomizing them, perhaps in
multiple ways \citep[see also][]{ImaDyk04}.

\subsection{Preprocessing via Matching}

The goal of matching is to preprocess the data prior to the parametric
analysis so that the relationship between $t_i$ and $X_i$ is
eliminated or reduced without introducing bias and inefficiency.  This
means that when matching we can select, duplicate, or selectively drop
observations from an existing sample without inducing bias, as long as
we do so using a rule that is a function only of $t_i$ and $X_i$ and
does not depend on the outcome variable $Y_i$.  \MatchIt\ provides,
implements, and evaluates the choice of these rules.  After matching,
the original dataset will be preprocessed so that $t_i$ and $X_i$ are
unrelated or less related than before. This implies that the treatment
and control groups have the same background characteristics, or,
formally $\tilde p(X\mid t=1) \approx \tilde p(X\mid t=0)$, where
$\tilde p$ refers to the observed empirical density of the data (think
histogram), rather than a population density.

The simplest way to obtain good matches (as defined above) is to use
one-to-one exact matching, which pairs each treated unit with one
control unit for which the values of $X_i$ are identical.  However,
with many covariates and finite numbers of potential matches, it is
often very difficult to obtain exact matches.  Fortunately, good
matching only requires that the empirical \emph{distribution} of $X$
given $t=0$ match that of $X$ given $t=1$, and so individual (exactly)
matched pairs are not required.  Indeed, many of the other methods
implemented in \MatchIt\ only attempt to balance the overall covariate
distributions, without necessarily finding one-to-one exact matches.

\subsection{Checking Balance}

The goal of a matching procedure is to replicate a randomized
experiment in terms of finding units who look as if they could have
been randomly assigned to treatment or control status.  That is, we
would like the distribution of covariates to be the same in the
matched treated and matched control groups. Thus, a crucial part of
any matching procedure is assessing how close the matches are in the
two groups, which we call the ``balance".  Because the outcome
variable is not used in the matching procedure, a variety of matching
methods can be assessed, and the matching procedure that leads to the
best balance chosen.  \MatchIt\ provides a number of ways to assess
the balance of covariates after matching, including numerical
summaries such as the standardized bias (difference in means divided
by the treated group standard deviation) and graphical summaries such
as quantile-quantile plots that compare the empirical distributions of
each covariate.  These diagnostics can be done on the covariates
included in the matching procedure, as well as on other covariates on
which close matches are desired.

\subsection{Conducting Analyses after Matching}

The most common way that parametric analyses are used to compute
quantities of interest is by holding constant some explanatory
variables, changing others, and computing predicted or expected values
and taking the difference or ratio.  In the case of causal inference,
this would probably mean looking at the effect on the expected value
of the outcome variable when changing $T$ from 0 to 1, while holding
constant the pretreatment control variables $X$ at their means
or medians.  This, and indeed any other ordinary procedure, would be a
perfectly reasonable way to proceed with analysis after matching.

Another way to proceed with analysis after \MatchIt\ is to compute the
average treatment effect on the treated.  For example, for the treated
group, the potential outcomes under control, $Y_{0i}$, are missing,
whereas the outcomes under treatment, $Y_{1i}$, are observed, and the
goal of the analysis is to impute the missing outcomes, $Y_{0i}$ in
observations where $T_i=1$.  We do this via simulation using a
parametric statistical model (as described below).  Once those
potential outcomes are imputed from the model, the estimate of
individual $i$'s treatment effect is $Y_{1i}-\widehat{Y}_{0i}$ where
$\widehat{Y}_{0i}$ is a simulation of the average missing potential
outcome for unit $i$ (that is it is a simulation of the value of the
dependent variable for unit $i$ under the counterfactual condition
where $T_i=0$).  The in-sample average treatment effect for the
treated individuals can then be obtained by averaging this
difference over all observations $i$ where in fact $T_i=1$.  (A similar
procedure can also be used to estimate various other quantities of
interest such as the average treatment effect for all observations.)
An advantage of this simulation approach is that the uncertainty
estimates such as standard errors and confidence intervals are
obtained easily by the usual rules in fitting the parametric model.

The imputation from the model can be done in at least two ways.
Recall that the model is used to impute \emph{the value that the
  outcome variable would take among the treated units if those treated
  units were actually controls}.  Thus, one reasonable approach would
be to fit a model to the whole set of matched data and create
simulated predicted values of the dependent variable for the treated
units with $T_i$ switched counterfactually from 1 to 0.  An
alternative approach would be to fit a model without $T$ by using only
the outcomes of the matched control units (i.e., using only
observations where $T_i=0$).  Then, given this fitted model, the
missing outcomes $Y_{i0}$ are imputed for the matched treated units by
using the values of the explanatory variables for the treated units.
The first approach will usually have lower variance, since all
observations are used, and the second may have less bias, since no
assumption of constant parameters is needed.  See \citet*{HoImaKin05}
for more details.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{User's Guide to \MatchIt}
\label{methods}

We adopt the same notation as in \citet*{HoImaKin05}. Unless otherwise
noted, let $i$ index the $n$ units in the dataset, $n_1$ denote the
number of treated units, $n_0$ denote the number of control units
(such that $n=n_0+n_1$), and $x_i$ indicate a vector of pretreatment
(or control) variables for unit $i$.  Let $t_i=1$ when unit $i$ is
assigned treatment, and $t_i=0$ when unit $i$ is assigned control.
(The labels ``treatment'' and ``control'' are arbitrary and can be
switched for convenience.)  Denote $y_{1i}$ as the potential outcome
of unit $i$ under treatment and $y_{0i}$ the potential outcome of unit
$i$ under control.  The variables $y_{1i}$ and $y_{0i}$ are jointly
unobservable, and for each $i$, we observe one
$y_i=t_iy_{1i}+(1-t_i)y_{0i}$, and not the other.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Example Data: National Supported Work Demonstration}
\label{subsec:lalonde}

For a running example, we use data from the job training program
analyzed in \citet{lalonde86} and \citet{DehWah99}.  A subsample of
the data consisting of the National Supported Work Demonstration (NSW)
treated group and the comparison sample from the Population Survey of
Income Dynamics (PSID) is included in \MatchIt.\footnote{This data
set, \texttt{lalonde}, was created using NSWRE74$\_$TREATED.TXT and
CPS3$\_$CONTROLS.TXT from
http://www.columbia.edu/$\sim$rd247/nswdata.}  The variables in this
dataset are described in Table~\ref{dwvars}.  One causal effect of
interest is the impact that participation in the job training program,
\texttt{treat == 1}, had on real earnings in 1978, \texttt{re78}, for
those that participated in the program.  The average treatment effect
on the treated (ATT) is defined as, 
\begin{align}
  \label{att}
  \text{ATT} & = \frac{1}{\sum_{i=1}^n t_i}\sum_{i:t_i=1} E[Y_i(1) - Y_i(0)],
\end{align}
where $Y_i(1)$ represents the potential outcome under the treatment of
the job program, and $Y_i(0)$ under control.  Note that the first term
inside the expectation (the right hand side of Equation~\ref{att}) is
\emph{observed}, whereas the second term is the \emph{unobserved}
counterfactual of real earnings if participants had not participated.
The nature of causal inference is that one of the two terms in the
difference will always be unobserved.  

\begin{table}[h]
\centering
\begin{tabular}{lp{3in}}
  \hline 
  \multicolumn{1}{l}{Variable name} & \multicolumn{1}{c}{Description} \\
  \hline
  \multicolumn{2}{l}{\textbf{Outcome variable ($Y$)}} \\ 
  \texttt{re78} & Real earnings (1978) \\ \\
  \multicolumn{2}{l}{\textbf{Treatment variable ($T$)}} \\
  \texttt{treat} & Treated in job training program from March 1975-June
  1977 (1 if treated, 0 if not treated)
  \\ \\
  \multicolumn{2}{l}{\textbf{Pre-treatment covariates ($X$)}} \\
  \texttt{age} & Age\\
  \texttt{educ} & Years of education \\
  \texttt{black} & Race black (1 if black, 0 otherwise) \\
  \texttt{hispan} & Race hispanic  (1 if Hispanic, 0 otherwise) \\
  \texttt{married} & Marital status (1 if married, 0 otherwise) \\
  \texttt{nodegree} & High school degree (1 if no degree, 0 otherwise)\\
  \texttt{re74} & Real earnings (1974) \\
  \texttt{re75} & Real earnings (1975) \\ 
  \hline
\end{tabular}\label{lalonde}
\caption{Description of Lalonde data \label{dwvars}}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Preprocessing via Matching}
\label{subsec:matching}

\texttt{matchit()} implements a variety of matching procedures.  A
general syntax is
<<results=hide, eval=FALSE>>=
m.out <- matchit(treat ~ x1 + x2, data = mydata)
@
where {\tt treat} is the dichotomous treatment variable, and {\tt x1}
and {\tt x2} are pre-treatment covariates.  This command creates the
\MatchIt\ object called \texttt{m.out}.  A quick summary of the
matching procedure can be printed on the screen by typing
<<results=hide, eval=FALSE>>=
m.out
@
or
<<results=hide, eval=FALSE>>=
print(m.out)
@
Examples of various matching procedures are given for the reminder of
this section, and Section~\ref{subsec:inputs} lists all possible
specifications of {\tt matchit()}.

\subsubsection{Exact Matching}
\label{subsubsec:exact}

The simplest version of matching is exact.  This technique matches
\emph{each} treated unit to \emph{all} possible control units with
exactly the same value on all the covariates, forming subclasses such
that within each subclass all units (treatment and control) have the
same covariate values.  Exact restrictions on a subset of covariates
can also be specified in nearest neighbor matching (see
Section~\ref{subsubsec:nearest}).

The following example script can be run by typing {\tt demo(exact)} at
the R prompt:
<<>>=
library(MatchIt)
data(lalonde)
m.out <- matchit(treat ~ educ + black + hispan, data = lalonde, method = "exact")
@

The object \texttt{m.out} contains all the information on the matched
units.  The matching forms all possible subclasses based on unique
values of the covariates in the right hand side of the formula; within
each subclass, all units have the same covariate values.  To obtain
basic information about the matching procedure:
<<>>=
m.out
@

The printout includes the original call to \MatchIt\ and the fact that
\Sexpr{sum(m.out$weights[m.out$treat==1]!=0)}
treatment units were exactly matched to \Sexpr{sum(m.out$weights[m.out$treat==0]!=0)} 
control units on race
and education. There was \Sexpr{sum(m.out$weights[m.out$treat==1]==0)}
treated unit and \Sexpr{sum(m.out$weights[m.out$treat==0]==0)}
control units that weren't matched,
and therefore are excluded from the matched data set. See
Sections~\ref{subsubsec:inputs-all}~and~\ref{subsubsec:inputs-exact}
for a list of complete input options for exact matching.  Now, proceed
to Section~\ref{subsec:balance} to learn about how the {\tt summary()}
command can be used with exact matching.

\subsubsection{Subclassification}
\label{subsubsec:subclass}

When there are many covariates (or many values of some covariates) on
which matches are desired, finding sufficient exact matches will often
be impossible.  In that case, subclassification is sometimes
desirable. Various subclassification schemes exist, including the one
based on a scalar distance measure such as the propensity
score estimated using the \texttt{distance} option (see
Section~\ref{subsubsec:inputs-all}).  Subclassification will form
subclasses based on this distance measure.  Within each subclass, the
distribution of covariates in the treatment and control groups should
be similar.

Subclassification is implemented in \MatchIt\ using \texttt{method =
  "subclass"}.  See also the sections on full matching (Section
\ref{subsubsec:full}) and nearest-neighbor matching (Section
\ref{subsubsec:nearest}), which provide additional ways of performing
subclassification.  The following example script can be run by typing
{\tt demo(subclass)} at the R prompt:
<<>>=
m.out <-  matchit(treat ~ re74 + re75 + educ + black + hispan + age, data = lalonde, 
                   method = "subclass")
@

The above syntax forms forms 6 subclasses, which is the default number
of subclases, based on a distance measure estimated using logistic
regression.  By default, each subclass will have approximately the
same number of treated units.  See
Sections~\ref{subsubsec:inputs-all}~and~\ref{subsubsec:inputs-subclass}
for a complete list of input options for subclassification.

Subclassification may also be used in conjunction with nearest
neighbor matching described below in
Subsection~\ref{subsubsec:nearest}, by leaving the default
of \texttt{method = "nearest"} but adding the option
\texttt{subclass}.  When you choose this command, \MatchIt\ matches in
the same way, but after the nearest neighbor matches are chosen it places them into
subclasses, and adds a variable to the output 
object with the subclass numbers.

\subsubsection{Nearest Neighbor Matching}
\label{subsubsec:nearest}

Nearest neighbor matching selects the $r$ best control matches for
each individual in the treatment group (excluding those discarded
using the \texttt{discard}) option (by default, $r=1$).  The matching is done using a
distance measure specified by the {\tt distance} option. Matches are
chosen for each treated unit one at a time, and at each matching step
we choose the control unit that is not yet matched but is closest to
the treated unit on the distance measure.  There are many variations
on nearest neighbor matching, which are described in further detail in
Sections~\ref{subsubsec:inputs-all}~and~\ref{subsubsec:inputs-nearest}.

Nearest neighbor matching is implemented in \MatchIt\ using the
\texttt{method="nearest"} option.  The following example script can be
run by typing {\tt demo(nearest)} at the R prompt.

To conduct propensity score matching with pre-treatment covariates
composed of real earnings in 1974 and 1975, education, race, and age:

<<>>=
m.out <- matchit(treat ~ re74 + re75 + educ + black + hispan + age, data = lalonde, method = "nearest")
@

\noindent You may again check basic statistics of the \MatchIt\ object by the
\texttt{print} command:
<<>>=
print(m.out)
@

We see that 185 control units were matched to the 185 treated units (a
``1-1'' match).  

\paragraph{Additional Examples}
Here, we illustrate various options of nearest neighbor matching by
providing additional examples based on the Lalonde data. Users should
refer to
Sections~\ref{subsubsec:inputs-all}~and~\ref{subsubsec:inputs-nearest}
for a complete list of options for nearest neighbor matching.

\begin{enumerate}

\item Nearest neighbor matching on propensity score estimated using
  logistic regression where 2 matches are chosen for each treated unit.
<<results=hide>>=
m.out1 <- matchit(treat ~ re74 + re75 + age + educ, data = lalonde, method = "nearest", distance = "logit", ratio=2)
@

\item Mahalanobis matching on {\tt re74} and {\tt re75}.
<<results=hide>>=
m.out <- matchit(treat ~ re74+re75, data=lalonde, method="nearest", distance="mahalanobis")
@

\item Mahalanobis matching on {\tt re74} and {\tt re75} within nearest
  neighbor matching on distance measure (propensity score), with restriction of exact
  matches on {\tt married}.
<<results=hide>>=
m.out2 <- matchit(treat ~ re74 + re75 + age + educ, data = lalonde, method = "nearest", distance = "logit", mahvars=c("re74", "re75"), exact=c("married"), caliper=.25)
@

\item Nearest neighbor matching after discarding all units outside of
  the common support of the estimated distance measure.
<<results=hide>>=
m.out3 <- matchit(treat ~ re74 + re75 + age + educ, data = lalonde, method = "nearest", distance = "logit", discard= "both")
@

\item Nearest neighbor matching with replacement where two control
  units are matched with one treated unit.
<<results=hide>>=
m.out4 <- matchit(treat ~ re74 + re75 + age + educ, data = lalonde, method = "nearest", distance = "logit", replace = TRUE, ratio = 2)
@

\item Nearest neighbor matching followed by formation of 5 subclasses
<<results=hide>>=
m.out5 <- matchit(treat ~ re74 + re75 + age + educ, data = lalonde, method = "nearest", distance = "logit", subclass=5)
@
\end{enumerate}

\subsubsection{Full Matching}
\label{subsubsec:full}

Full matching is a a particular type of subclassification that uses
all treated and control units \citep{Rosenbaum02, Hansen04}.  A fully
matched sample is composed of matched sets, where each matched set
contains either one treated unit and one or more controls (or one
control unit and one or more treated units).  The only units not
placed into a subclass will be those discarded (if a \texttt{discard}
option was specified) because they are outside of common support.
Full matching is optimal in terms of minimizing a weighted average of
the estimated distance measure between each treated subject and each
control subject within each subclass.  See
Sections~\ref{subsubsec:inputs-all}~and~\ref{subsubsec:inputs-full}
for a complete list of optional inputs for full matching.

Full matching can be performed with \MatchIt\ by setting
\texttt{method = "full"}.  We use an add-on package called
\texttt{optmatch} \citep{Hansen04}, which must be installed separately
by typing at the R command prompt, 

%can we do this automatically if its needed, like we do in zelig?  
<<results=hide,eval=FALSE>>=
install.packages("optmatch", contriburl =
"http://www.stat.lsa.umich.edu/~bbh/optmatch") 
@ 

For more information
about the package, see
\hlink{http://www.stat.lsa.umich.edu/\~{}bbh/optmatch.html}{http://www.stat.lsa.umich.edu/\~bbh/optmatch.html}.
The following example script can be run by typing {\tt demo(full)} at
the R prompt.  We first load the Lalonde data, confuct full matching
(using the propensity score based on logistic regression), and then
print a short summary.

<<>>=
m.out <- matchit(treat ~ age + educ + black + hispan + married + nodegree + re74 + re75, data = lalonde, method = "full", distance = "logit")
m.out
@

We see that the matching has utilized all units (the treated and
control group sample sizes are the same for the full and matched
samples). 

\subsubsection{Optimal Matching}
\label{subsubsec:optimal}

The default nearest neighbor matching method in \MatchIt\ is
``greedy'' matching, where the closest control match for each treated
unit is chosen one at a time, without trying to minimize a global
distance measure.  Another method, ``optimal'' matching, finds the
matched samples with the smallest average absolute distance between
each matched pair.  With large control pools, greedy and optimal
matching may lead to very similar (or the same) sets of matches;
\citet{GuRos93} have shown that greedy and optimal matching generally
choose the same sets of controls for the matched samples, but that
optimal matching does a better job of minimizing the distance within
each pair.  In addition, optimal matching can be particularly helpful
when there are not many appropriate control matches for the treated
units.  See \cite{GuRos93} or \cite{Rosenbaum02} for more information
on optimal matching. See
Sections~\ref{subsubsec:inputs-all}~and~\ref{subsubsec:inputs-optimal}
for a complete list of optional inputs for optimal matching.

Optimal matching is performed with \MatchIt\ by setting \texttt{method
  = "optimal"}.  We use an add-on package called \texttt{optmatch}
  \citep{Hansen04}, which must be installed separately by typing at
  the R command prompt, 

%** can we do this automatically if its needed, like we do in zelig?  
<<results=hide,eval=FALSE>>=
  install.packages("optmatch", contriburl =
  "http://www.stat.lsa.umich.edu/~bbh/optmatch") 
@ 

For more
  information about the package, see
  \hlink{http://www.stat.lsa.umich.edu/\~{}bbh/optmatch.html}{http://www.stat.lsa.umich.edu/\~bbh/optmatch.html}.
  The following example script (optimal ratio matching based on the
  propensity score from the logistic regression) can be run by typing
  {\tt demo(optimal)} at the R prompt.
<<>>=
m.out <- matchit(treat ~ re74 + re75 + age + educ, data = lalonde, method = "optimal", distance = "logit", ratio = 2)
m.out
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Checking Balance}
\label{subsec:balance}

In \MatchIt, there are two ways to check balance after any matching
procedure. Given the \MatchIt\ output object {\tt m.out}, one can use
the following commands
\begin{enumerate}
\item \texttt{summary(m.out)} gives numerical summaries of the
  resulting balance of covariates.

\item \texttt{plot(m.out)} gives graphical summaries to assess balance
  of covariates.
\end{enumerate}
Below, we give three examples (exact matching, nearest neigbor
matching, and sublassification) to illustrate the use of these two
functions. Similar commands can be used for all other matching
procedures, and they will give similar outputs. See
Section~\ref{subsec:outputs} for details.

\paragraph{Examples}
\begin{enumerate}
%%
%% this is from exact matching
%%
\item Using the example of exact matching from
  Section~\ref{subsubsec:exact}, we obtain more information on the
  matching using the {\tt summary()} command.  To also show the
  covariates values in each subclass, we use the \texttt{covariates =
    TRUE} option:
<<>>=
m.out <- matchit(treat ~ educ + black + hispan, data = lalonde, method = "exact")
summary(m.out, covariates = TRUE)
@

\MatchIt\ has created 25 subclasses where the values of the race and education
covariates are equal.  The \MatchIt\ output object will include
\texttt{weights} and \texttt{subclass}, which can be used to identify
which units were put into the same subclass.  Units that did not have
the same covariate values as anyone in the other treatment group have
\texttt{subclass = NA}.

For example, we can use the {\tt sublass} component of {\tt m.out} to
identify which units are in each subclass and to verify their
covariate values.  To see the ID numbers of the first 10 units in subclass
1, in which all subjects are black and have 11 years of education
(``NSW'' refers to the National Supported Work Demonstration
participants):

<<>>=
row.names(m.out$X)[m.out$subclass==1][1:10]
@

We can also confirm the covariate values of the units in each
subclass.  For example, to see the covariate values of the first 5
units in subclass 2 (``PSID'' refers to individuals in the Panel
Survey of Income Dynamics):

<<>>=
m.out$X[m.out$subclass==2 & !is.na(m.out$subclass),][1:5,]
@

%%%
%%% this is from nearest neighbor
%%%

\item For all other types of matching, the \texttt{summary()} command first gives measures of the
  balance between the treated and control groups in the full
  (original) data set, and then the same measures of balance in the
  matched data set.  If the matching worked well, the measures of balance
  should be smaller in the matched data
  set as compared with the full data set.  

  To illustrate this we use the example of nearext neighbor matching from Section \ref{subsubsec:nearest}:
<<>>=
m.out <- matchit(treat ~ re74 + re75 + educ + black + hispan + age, data = lalonde, method = "nearest")
summary(m.out)
@

The \texttt{summary()} command provides simple statistics of the
propensity score and the covariates used in the matching for the full
and matched samples, including means, standardized bias, and
Quantile-Quantile (Q-Q) plot statistics.  These are used to assess
whether there was a reduction in bias in the covariates.  The
\texttt{summary} command will additionally report (a) the original
call of the \MatchIt\ object, (b) how many units were matched,
unmatched, or discarded due to the \texttt{discard} option (described
below), and (c) the percent improvement in balance for each of the
balance measures, defined as $100((|a|-|b|)/|a|)$, where $a$ is the
balance before and $b$ is the balance after matching.

For each set of units (full sample and matched sample), the following
statistics are provided: the ``Means Treated" and ``Means Control"
columns show the weighted means in the treated and control groups; the
``Treated SD" is the standard deviation of the covariate in the set of
treated units; the ``Std. Bias" is the difference in means in the
treated and control groups, divided by the ``Treated SD" calculated
using all treated units.  The same standard deviation is used for
calculating the standardized bias in the full data and the matched
data set so that the success of the matching at reducing bias in the
covariate means can be easily assessed; standardizing by the same
quantity puts the two differences in means on the same scale.  Good
matches will generally have standardized biases less than
approximately 0.25; values greater than that imply that the groups
have means that are more than a quarter of a standard deviation apart.

The final three columns of the summary output give summary statistics
of a Q-Q plot (see below for more information on these plots). Those
columns give the median, mean, and maximum orthogonal deviations from
the 45-degree line of the Q-Q plot.  If the empirical distributions of
the two groups (treated and control) were exactly the same, all points
would lie on the 45-degree line and thus all of these distances would
be 0.  Values greater than 0 indicate deviations between the groups in
some part of the empirical distributions.  The plots themselves,
described below, can provide further insight into which part of the
covariate distribution has differences between the groups.

In this example of nearest neighbor matching, we see that the matching
has reduced the bias in the propensity score from 1.79 to 0.95 and has
reduced the bias in some of the covariates (e.g., 1974 and 1975
income).  Job training participants on average earned roughly \$3,524
less in 1974 and \$934 less in 1975 than non-participants, in the full
sample.  In the matched sample, the earnings difference is reduced to
\$371 in 1974 and \$428 in 1975.  This one-to-one matching algorithm
has thus chosen 185 control individuals who are more similar to the
treated group in 1974 income and 1975 income, which is summarized by
the $89.5$ and $54.2$ percent balance improvement in these covariates.
However there are still fairly large differences on some of the
covariates, such as the race variables.  In this situation, if close
matches on the race variables are desired, it may make sense to try
Mahalanobis or exact matching on the race variables in addition to the
propensity score matching.  The large remaining bias in the propensity
score (0.95 standard deviations) also indicates that it may be
desirable to do subclassification instead of or in addition to the
matching, as described below.

Two options to the \texttt{summary} command can also help with
assessing balance and respecifying the propensity score model, as
necessary.  First, the {\tt interactions=T} option with {\tt summary}
shows the balance of all squares and interactions of the covariates
used in the matching procedure.  Large differences in higher order
interactions usually are a good indication that the assignment model
needs to be respecified.  Similarly, the {\tt addlvariables} option
with {\tt summary} will provide balance measures on additional
variables not included in the original matching procedure.  If a
variable (or interaction of variables) not included in the original
distance measure has large imbalances in the matched groups, including
that variable in the next model specification may improve the
resulting balance on that variable.  \cite{DehWah99} provide a
detailed example of a propensity score specification algorithm.
Because the outcome variable is not used in the matching procedure, a
variety of matching methods can be tried, and the one that leads to
the best resulting balance chosen.

%as discussed in
%Section \ref{pscorespec}.

We can also examine the balance graphically using the \texttt{plot()}
command, which provides two types of plots: jitter plots of the
distance measure, and Q-Q plots of each covariate.
Figures~\ref{diagqqnn} and~\ref{diagjitternn} display these two sample
plots.  In the jitter plot, you may identify units by observation name
by clicking the first mouse button near the units.

<<results=hide,eval=FALSE>>=
plot(m.out)
plot(m.out, type="jitter")
@

\begin{figure}[tbp]
  \begin{center}
%    \rotatebox{270}{\includegraphics[height=2.85in,angle=0]{figs/subclass1}}
    \includegraphics[scale=0.25]{figs/qqplotnn}
    \includegraphics[scale=0.25]{figs/qqplotnn2} 
    \hfill
    \caption{Sample diagnostic QQ plots: Nearest Neighbor matching
      with the \MatchIt\ call \texttt{matchit(treat ~ re74 + re75 + educ
        + black + hispan + age, data=lalonde, method="nearest")}.}
\label{diagqqnn}
\end{center}
\end{figure}

\begin{figure}[tbp]
  \begin{center}
%    \rotatebox{270}{\includegraphics[height=2.85in,angle=0]{figs/subclass1}}
    {\includegraphics[scale=0.5]{figs/jitterplotnn}}
    \hfill
    \caption{Sample diagnostic jitter plot: Nearest Neighbor matching
      with the \MatchIt\ call \texttt{matchit(treat ~ re74 + re75 +
        educ + black + hispan + age, data=lalonde, method="nearest")}.
      Matched units shown in black, unmatched units shown in grey.}
\label{diagjitternn}
\end{center}
\end{figure}

The balance of the individual covariates is shown in the Q-Q plots.
If the empirical distributions are the same in the treated and control
groups, the points would all lie on the 45 degree line.  Deviations
from the 45 degree line indicate differences in the empirical
distribution.  The jitter plot shows the overall distribution of
propensity scores in the treated and control groups.  In the jitter
plot, the size of each diamond is proportional to the weight given to
that unit; matched units are in black while unmatched units are in
grey.

Examining these graphs, we see that the matched samples are fairly
well matched on the propensity score and the income variables, but
that there are some remaining imbalances in the race and age
variables, as was also seen using the \texttt{summary} command.

\item Now for subclassification, using the example from
  Section~\ref{subsubsec:subclass}, we check the balance of
  covariates using the \texttt{summary()} and \texttt{plot()} commands.
%%
%% this is the output of subclassification
%%
<<>>=
m.out <-  matchit(treat ~ re74 + re75 + educ + black + hispan + age, data = lalonde, method = "subclass")
summary(m.out)
@

The \texttt{summary} output for subclassification is the same as that
for nearest neighbor matching, except that the balance statistics are
shown separately for each subclass, and the overall balance in the
matched samples is calculated by aggregating across the subclasses, where each subclass is weighted
by the number of units in the subclass.
Consistent with the calculations for the full and matched samples, the
standardized bias within each subclass is also calculated using the
standard deviation of the full treated group, again so that the
differences in means are all scaled by the same amount and not
affected by changes in sample sizes.

In this example, the bias between the groups within each sublcass is
generally small, with the exception of Subclass 1, which has a large
number of control units with small propensity scores.  The percent
balance improvement also indicates that the subclassification has been
successful at forming subclasses within which the distribution of
covariates is more similar than in the full data set.  In particular,
80 to 90 percent reduction in the standardized bias was achieved in 4
of the 6 covariates through subclassification; little bias reduction
was achieved on the education variable, which had very small bias to
start (standardized bias of only 0.055 in the full data set).  For
this example, it appears as though subclassification has been able to
form better matched samples than the simple 1-1 nearest neighbor
matching method described above.

We can also examine the balance graphically.  Figures~\ref{diagqqsub}
and \ref{diagjittersub} display the two diagnostic plots.  With
subclassification, separate Q-Q plots are printed for each subclass;
for each, the graphs shown in the left-hand column are those for the
full data set.  The jitter plot is the same as that for nearest
neighbor matching, with the addition of vertical lines indicating the
subclass cut-points.

<<results=hide>>=
m.out <- matchit(treat ~ re74 + re75 + educ + black + hispan + age, data = lalonde, method = "subclass")
@
<<results=hide, eval=FALSE>>=
plot(m.out)
plot(m.out, type="jitter")
@

%<<fig=TRUE, width=8, height=5, prefix.string=figs/, echo=FALSE>>=
%plot(m.out)
%@
%<<fig=TRUE, width=8, height=5, prefix.string=figs/>>=
%plot(m.out, type="jitter")
%@

\begin{figure}[tbp]
  \begin{center}
    %\rotatebox{270}{\includegraphics[height=2.85in,angle=0]{figs/subclass1}}
    \includegraphics[scale=.25]{figs/qqplotsub}
    \includegraphics[scale=.25]{figs/qqplotsub2}
    \hfill
\caption{Sample diagnostic QQ plots: Subclassification with
      \MatchIt\ call \texttt{matchit(treat ~ re74 + re75 + educ +
        black + hispan + age, data = lalonde, method = "subclass")} followed by plot(m.out).}
\label{diagqqsub}
\end{center}
\end{figure}

\begin{figure}[tbp]
  \begin{center}
    %\rotatebox{270}{\includegraphics[scale=0.5,angle=0]{figs/subclass1}}
    {\includegraphics[scale=0.5]{figs/jitterplotsub}}
    \hfill
\caption{Sample diagnostic jitter plot: Subclassification with
      \MatchIt\ call \texttt{matchit(treat ~ re74 + re75 + educ +
        black + hispan + age, data = lalonde, method = "subclass") followed by plot(m.out, type="jitter")}.
      Vertical lines indicate the subclass cut points and the area of
      each diamond is proportional to the weights of the matched units
      for each subclass.  Unmatched units would be shown in grey.}
\label{diagjittersub}
\end{center}
\end{figure}

In Figure \ref{diagqqsub} we see that the empirical distributions of
the treated and control units are much more similar in Subclass 3
(shown in the ``Matched" column of figures) than they are in the full
data set (shown in the ``Raw" column of figures).  We see that in this
case, the distributions of most of the covariates are very similar in
Subclass 3, with the exception of \texttt{age}, which on which the
treated units generally have larger values than the control units
(indicated by the points falling above the 45 degree line).  The
jitter plot indicates that using the \texttt{discard} option may be
desirable here, to reduce any bias due to the many control units with
low propensity scores.

\end{enumerate}

%%%
%%% this is from full matching. probably not necessary.
%%%
%
%\begin{verbatim}
%## balance diagnostics through statistics
%<<>>=
%m.out <- matchit(formula = treat ~ age + educ + black + hispan + married +   
%        nodegree + re74 + re75, data = lalonde, method = "full", distance = "logit")
%summary(m.out)
%@
%** we need to explain the col titles or refer back to the intro
%   section (to be added) to the user's guide
%There has been significant reduction in standardized bias (and mean
%deviation from the 45 degree line in the quantile-quantile plot) from
%the full matching: the percent improvement is nearly 100 percent.  The
%diagnostics are slightly different with full matching as compared with
%the previous matching methods we have discussed; since many subclasses
%will have only one treated or one control unit it is not possible to
%do the weighted comparisons done for standard subclassification.
%** {\bf  Dan, what did we decide to do?}
%
%Finally, we can obtain a graphical summary of resulting balance via
%the usual {\tt plot()} function.
%\begin{verbatim}
%## balance diagnostics through graphics
%> plot(m.out)
%\end{verbatim}

%\includegraphics[scale=0.5]{figs/full1}
%\includegraphics[scale=0.5]{figs/full2}
%\includegraphics[scale=0.5]{figs/full3}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Conducting Analyses after Matching}
\label{subsec:analysis}


\input{matchit2zeligsw}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Reference Manual}
\label{sec:reference}

\subsection{Inputs}
\label{subsec:inputs}

The main command, \texttt{matchit()}, can be used to implements any of
the matching procedures:
<<results=hide, eval=FALSE>>=
m.out <- matchit(formula, data, method = "nearest", distance = "logit", distance.options=list(), discard = "none", reestimate = FALSE, ...)
@
The command takes some inputs that are common to all matching
procedures and other inputs specific to particular procedures.  The
outputs are standard across all procedures.  We organize the reference
manual in these categories.

\subsubsection{All Matching Methods}
\label{subsubsec:inputs-all}

\begin{enumerate}
  
\item \texttt{formula} takes the usual syntax of R formula, {\tt treat
    \~\ x1 + x2}, where {\tt treat} is a binary treatment indicator
  and {\tt x1} and {\tt x2} are the pre-treatment covariates. Both the
  treatment indicator and pre-treatment covariates must be contained
  in the same data frame, which is specified as {\tt data} (see
  below).  All of the usual R syntax for formulas work here. For
  example, {\tt x1:x2} represents the first order interaction term
  between {\tt x1} and {\tt x2}, and {\tt I(x1 \^\ 2)} represents the
  square term of {\tt x1}. See {\tt help(formula)} for details.
  
\item \texttt{data} specifies the data frame containing the variables
  called in {\tt formula}.  You may find it helpful for the
  diagnostics to specify observation names in the data frame (see
  Section~\ref{rnames}).
  
\item \texttt{method} specifies a matching method. Currently,
  \texttt{exact} (exact matching), \texttt{full} (full matching),
  \texttt{nearest} (nearest neighbor matching), \texttt{optimal}
  (optimal matching), and \texttt{subclass} (subclassification) are
  available. The default is \texttt{nearest}. Note that within each of
  these matching methods, \MatchIt\ offers a variety of options.  See
  Section \ref{methods} for more details.
  
\item \texttt{distance} specifies the method used to estimate the
  distance measure. The default is logistic regression, {\tt logit}.
  Before using any of these techniques, it is best to understand the
  theoretical groundings of these techniques and to evaluate the
  results.  Most of these methods (such as logistic or probit
  regression) are estimating the propensity score, defined as the
  probability of receiving treatment, conditional on the covariates
  (\cite{RosRub83}).  The distance measures used are the predicted
  probabilities from the model (the propensity scores).  Currently,
  the following methods are available:
  \begin{enumerate}
  \item {\tt mahalanobis} computes the Mahalanobis distance measure
    ({\tt mahalanobis()} in the {\tt stats} package).
  \item binomial generalized linear models with various links ({\tt
      glm()} in the {\tt stats} package); \texttt{logit} (logistic
    link), {\tt linear.logit} (logistic link with linear propensity
    score)\footnote{The linear propensity scores are obtained by
      transforming back onto a linear scale}, \texttt{probit} (probit
    link), {\tt linear.probit} (probit link with linear propensity
    score), {\tt cloglog} (complementary log-log link), {\tt
      linear.cloglog} (complementary log-log link with linear
    propensity score), {\tt log} (log link), {\tt linear.log} (log
    link with linear propensity score), {\tt cauchit} (Cauchy CDF
    link), {\tt linear.cauchit} (Cauchy CDF link with linear
    propensity score).

  \item binomial generalized additive model with various links ({\tt
      gam()} in the {\tt mgcv} package); \texttt{GAMlogit} (logistic
    link), {\tt GAMlinear.logit} (logistic link with linear propensity
    score), \texttt{probit} (probit link), {\tt GAMlinear.probit}
    (probit link with linear propensity score), {\tt GAMcloglog}
    (complementary log-log link), {\tt GAMlinear.cloglog}
    (complementary log-log link with linear propensity score), {\tt
      GAMlog} (log link), {\tt GAMlinear.log} (log link with linear
    propensity score), {\tt GAMcauchit} (Cauchy CDF link), {\tt
      GAMlinear.cauchit} (Cauchy CDF link with linear propensity
    score). \citet{HasTib90,BecJac98} and many others discuss the
    generalized additive models.

  \item \texttt{nnet}, neural network model ({\tt nnet()} in the {\tt
      nnet} package).
    \citet{BecKinZen00,Bishop95,KinZen02,White92,Zeng99} among many
    others discuss neural networks.
  
  \item \texttt{rpart}, classification trees ({\tt rpart()} in the
    \texttt{rpart} package). \citet{BreFriOls84,RugKimMar03} and many
    others discuss classification trees.
  \end{enumerate}
  
\item \texttt{distance.options} specifies the optional arguments that
  are passed to the model for estimating the distance measure. The
  input to this argument should be a list.  For example, if the
  distance measure is estimated with a logistic regression, users can
  increase the maximum IWLS iterations by \texttt{distance.options =
    list(maxit = 5000)}.

\item \texttt{discard} specifies whether to discard units that fall
  outside some measure of support of the distance score before
  matching, and not allow them to be used at all in the matching
  procedure.  Note that discarding units may change the quantity of
  interest being estimated.
  \begin{itemize}
  \item \texttt{none} (default) discards no units before matching.
    Use this option when the units to be matched are substantially
    similar, such as in the case of matching treatment and control
    units from a field experiment that was close to (but not fully)
    randomized (e.g., \citealt{Imai05}), when caliper matching will
    restrict the donor pool, or when you do not wish to change the
    quantity of interest and the parametric methods to be used
    post-matching can be trusted to extrapolate.
  \item \texttt{both} discards all units (treated and control) that
    are outside the support of the distance measure. Use this option
    when the units to be matched are substantially different (when
    there is a large degree of non-overlapping support on the distance
    score), such as in the case of measuring the effect of democracy
    on economic growth.
  \item \texttt{control} discards only control units outside the
    support of the distance measure of the treated units.  Use this
    option when the average treatment effect on the treated is of most
    interest and when unwilling to discard non-overlapping treatment
    units (which would change the quantity of interest), such as
    possibly in the case of the effect of job training on those
    individuals that actually participated in a job evaluation program
    or a drug study where interest is in all patients treated with the
    drug.
  \item \texttt{treat} discards only treated units outside the support
    of the distance measure of the control units.  Use this option
    when the average treatment effect on the control units is of most
    interest and when unwilling to discard control units.
  \item \texttt{convex.hull} discards control units not within the
    convex hull of the treated units using the method developed in
    \citep{KinZen04}.
  \end{itemize}
  
\item \texttt{reestimate} specifies whether the model for distance
  measure should be re-estimated after units are discarded. The input
  must be a logical value. The default is \texttt{FALSE}.
  Re-estimation may be desirable for efficiency reasons, especially if
  many units were discarded and so the post-discard samples are quite
  different from the original samples.

\item \texttt{verbose} specifies whether or not to print out comments
  indicating the status of the matching. The input must be a logical
  value. The default is \texttt{FALSE}.
\end{enumerate}

\subsubsection{Exact Matching}
\label{subsubsec:inputs-exact}

Exact matching is implemented in \MatchIt\ using \texttt{method =
  "exact"}.  Exact matching will be done on all covariates included on
the right-hand side of the \texttt{formula} specified in the \MatchIt\
call.  No \texttt{distance} option is used for exact matching, and
there are no additional options for exact matching.

\subsubsection{Subclassification}
\label{subsubsec:inputs-subclass}

\begin{enumerate}
\item \texttt{subclass} is either (1) a scalar, specifying the number
  of subclasses, or (2) a vector of probabilities bounded between 0
  and 1, to create quantiles of the distance measure using the units
  in the group specified by \texttt{sub.by}.  The default is
  \texttt{subclass = 6}.
\item \texttt{sub.by} specifies by what criteria to subclassify:
  \texttt{"treat"} indicates by the number of treatment units
  (default), \texttt{"control"} indicates by the number of control
  units, and \texttt{"all"} indicates by the total number of units.
\end{enumerate}

\subsubsection{Nearest Neighbor Matching}
\label{subsubsec:inputs-nearest}

\begin{enumerate}
\item \texttt{m.order}  specifies the order in which to match
  treatment units with control units:
  \begin{itemize}
  \item {\tt "largest"} indicates matching from the largest value of
    the distance measure to the smallest. This is the default.
  \item {\tt "smallest"} indicates matching from the smallest value of
    the distance measure to the largest.
  \item {\tt "random"} indicates matching in random order.
  \end{itemize}
\item \texttt{replace} specifies whether each control unit can be
  matched to more than one treated unit.  For matching ``with
  replacement'', \texttt{replace = TRUE}.  If each control is to be
  used as a match at most once (``without replacement''), \texttt{replace
    = FALSE}. The default is {\tt FALSE}.
\item \texttt{ratio} specifies the number of control units to match to
  each treated unit, default=1.  If matching is done without
  replacement and there are fewer control units than ratio times the
  number of eligible treated units (i.e., there are not enough control 
  units for the specified method), then the higher ratios will have
  \texttt{NA} in place of the matching unit number in
  \texttt{match.matrix}.
\item \texttt{exact} specifies variables on which to perform exact
  matching within the nearest neighbor matching.  If \texttt{exact} is
  specified, only matches that exactly match on the covariates in
  \texttt{exact} will be allowed.  Within the matches that match on
  the variables in \texttt{exact}, the match with the closest distance
  measure will be chosen.  \texttt{exact} should be entered as a
  vector of variable names (\texttt{exact = c("X1", "X2")}) that are
  names of variables in \texttt{data}.
\item \texttt{caliper} specifies the number of standard deviations of
  the distance measure within which to draw control units, default=0.
  If a caliper is specified, the matches are restricted to being
  within the caliper and a control unit within the caliper for a
  treated unit is randomly selected as the match for that treated
  unit.  If \texttt{caliper != 0}, there are two additional options:
  \begin{itemize} 
  \item \texttt{calclosest} specifies whether to take the nearest
    available match if no matches are available within the
    \texttt{caliper}. The default is {\tt FALSE}.
  \item \texttt{mahvars} specifies variables on which to perform
    Mahalanobis-metric matching within each caliper (default=NULL).
    Variables should be entered as a vector of variable names
    (\texttt{mahvars=c("X1","X2")}) that are names of variables in
    \texttt{data}.  If \texttt{mahvars} is specified without
    \texttt{caliper}, the caliper is set to 0.25.
  \end{itemize}
\item \texttt{subclass} and \texttt{sub.by}.  See Section
  \ref{subsubsec:subclass} for more details on these options.  If a
  \texttt{subclass} is specified within \texttt{method = "nearest"},
  the matched units will be placed into subclasses after the nearest
  neighbor matching is completed.
\end{enumerate}


\subsubsection{Full Matching}
\label{subsubsec:inputs-full}

\begin{enumerate}
\item {\tt ...} represents additional inputs that can be passed to the
  {\tt fullmatch()} function in the {\tt optmatch} package. See {\tt
    help(fullmatch)} for details.
\end{enumerate}

\subsubsection{Optimal Matching}
\label{subsubsec:inputs-optimal}

The available options are listed below.
\begin{enumerate}
\item {\tt ratio} specifies the number of control units to be matched
  to each treatment unit, the default is {\tt 1}.
\item {\tt ...} represents additional inputs that can be passed to the
  {\tt fullmatch()} function in the {\tt optmatch} package. See {\tt
    help(fullmatch)} for details.
\end{enumerate}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Outputs}
\label{subsec:outputs}

\subsubsection{Output Object Contents}

Regardless of the type of matching performed, the \texttt{matchit}
output object contains the following elements:

\begin{enumerate}
\item \texttt{call} provides the original {\tt matchit()} call.
  
\item \texttt{formula} shows the formula used to specify the model for
  estimating the distance measure.
  
\item \texttt{model} stores the output of the model used to estimate
  the distance measure.  \texttt{summary(m.out\$model)} will give the
  summary of the model where \texttt{m.out} is the output object from
  \texttt{matchit()}.
  
\item \texttt{match.matrix} is an $n_1$ by \texttt{ratio} matrix
  where:
  \begin{itemize}
  \item the row names, which can be obtained through
    \texttt{row.names(match.matrix)}, represent the names of the
    treatment units, which come from the data frame specified in
    \texttt{data} (to learn how to do this, see Section~\ref{rnames}).
  \item each column stores the name(s) of the control unit(s) matched
    to the treatment unit of that row. For example, when the
    \texttt{ratio} input for nearest neighbor or optimal matching is
    specified as 3, the three columns of \texttt{match.matrix}
    represent the three control units matched to one treatment unit).
  \item \texttt{NA} indicates that the treatment unit was not matched.
  \end{itemize}
   
\item \texttt{discarded} is a vector of length $n$ that displays
  whether the units were ineligible for matching due to common support
  restrictions.  It equals \texttt{TRUE} if unit $i$ was discarded,
  and it is set to \texttt{FALSE} otherwise.
  
\item \texttt{distance} is a vector of length $n$ with the estimated
  distance measure for each unit.
  
\item \texttt{weights} is a vector of length $n$ that provides the
  weights assigned to each unit in the matching process.  Unmatched
  units have weights equal to $0$. Matched treated units have weight
  $1$.  Each matched control unit has weight proportional to the
  number of treatment units to which it was matched, and the sum of
  the control weights is equal to the number of uniquely matched
  control units. See Section~\ref{subsec:weights} for more details.
  
\item \texttt{subclass} contains the subclass index in an ordinal
  scale from 1 to the total number of subclasses as specified in
  \texttt{subclass} (or the total number of subclasses from full or
  exact matching).  Unmatched units have \texttt{NA}.
  
\item \texttt{q.cut} gives the subclass cut-points that classify the
  distance measure.
  
\item \texttt{treat} stores the treatment indicator from \texttt{data}
  (the left-hand side of \texttt{formula}).
 
\item \texttt{X} stores the covariates used for estimating the
  distance measure (the right-hand side of \texttt{formula}).  When
  applicable, \texttt{X} is augmented by covariates contained in
  \texttt{mahvars} and \texttt{exact}. 
\end{enumerate}


\subsubsection{{\tt summary()}}
The \texttt{summary} command returns more information about the
\MatchIt\ model.  Optional inputs are:

\begin{enumerate}
\item \texttt{interactions}, which is an option to calculate summary
  statistics in \texttt{sum.all} and \texttt{sum.matched} for all
  covariates, their squares, and two-way interactions when
  \texttt{interactions=TRUE} and only the covariates themselves when
  \texttt{interactions=FALSE} (default).
\item \texttt{addlvariables}, which may contain additional variables
  on which to calculate the diagnostic statistics (in addition to the
  variables included in the matching procedure).  By default,
  \texttt{addlvariables=NULL}.  \texttt{addlvariables} must be
  specified as a data frame, with the same number of units and units
  in the same order as in the data set sent to \MatchIt .
\end{enumerate}

The \texttt{summary} call returns, when applicable:

\begin{enumerate}
\item The original assignment model call.
\item \texttt{sum.all} is a data frame that contains variable names
  and interactions down the row names, and summary statistics on
  \emph{all observations} in each of the columns.  The columns in
  \texttt{sum.all} contain \footnote{The output for full matching is
    slightly different from that described here; see Section
    \ref{subsubsec:full} for details.}:
  \begin{itemize}
  \item means of all covariates $X$ for treated and control units,
    where \texttt{Means Treated}$= \mu_{X|T=1} = \frac{1}{n_1}
    \sum_{T=1} X_i$ and \texttt{Means Control}$= \mu_{X|T=0} =
    \frac{1}{n_0} \sum_{T=0} X_i$,
  \item standard deviation in the treated group for all covariates $X$,  
	$\quad s_{x|T=1} = \sqrt{\frac{\sum_{i \in \{i: T_i=1\}}
        X_i - \mu_{X|T=1}}{n_1-1} }.$
  \item summary statistics from a Q-Q plot, which compares treated and
    control covariate distributions, where \texttt{QQ Med}, \texttt{QQ
      Mean}, and \texttt{QQ Max} indicate the median, mean, and
    maximum orthogonal deviations from the 45 degree line of a Q-Q
    plot.
  \item standardized bias statistics, $${\rm Std.
      Bias}=\frac{\mu_{X|T=1} - \mu_{X|T=0}}{s_{x|T=1}}.$$
  \end{itemize}
  
\item \texttt{sum.matched} is a data frame which contains variable
  names down the row names, and summary statistics on only the
  \emph{matched observations} in each of the columns.  Specifically,
  the columns in \texttt{sum.matched} contain the following
  elements\footnote{The values output for full matching are slightly
    different from that described here; see Section \ref{subsubsec:full}
    for details}:
  \begin{itemize}
  \item weighted means for matched treatment units of all covariates
    $X$ and their interactions, where \texttt{Means Treated}$=
    \mu_{wX|T=1} = \frac{1}{n_1} \sum_{T=1} w_iX_i$ and \texttt{Means
      Control}$=\mu_{wX|T=0} = \frac{1}{n_0} \sum_{T=0} w_iX_i$,
  \item weighted standard deviations in the matched treated group 
   for all covariates $X$, where \texttt{SD} $= 
    s_{wX} =
    \sqrt{\frac{1}{n} \sum_{i} (w_iX_i - \overline{X}^*)^2}$, where
    $\overline{X}^*$ is the weighted mean of $X$ in the matched treated group.
  \item standardized bias statistics \texttt{Std.
      Bias}$=\frac{\mu_{wX|T=1} - \mu_{wX|T=0}}{s_{x|T=1}}$, and
  \end{itemize}
  where $w$ represents the vector of \texttt{weights}.
  
\item \texttt{reduction} shows the percent bias reduction achieved in
  each of the balance measures in \texttt{sum.all} and
  \texttt{sum.matched}, defined as $100(|a|-|b|)/|a|$, where $a$ was
  the value of the balance measure before matching and $b$ is the
  value of the balance measure after matching.  Because the difference in means and the standardized bias
  differ only by a constant (the standard deviation in the full treated group), the percent reduction in bias
  is the same for these two measures, and thus is only printed out once.

\item \texttt{nn} gives the sample sizes in the full and matched
  samples and the number of discarded units, by treatment and control.
  
\item \texttt{q.table} is an array that contains the same information
  as \texttt{sum.matched} by subclass.
  
\item \texttt{qn} gives the sample sizes in the full and matched
  samples and the number of discarded units, by subclass and by
  treatment and control.
\item \texttt{match.matrix} from the {\texttt matchit} output.
\end{enumerate}

\subsubsection{{\tt plot()}}

The \texttt{plot} command allows you to check the distributions of
covariates in the assignment model, squares, and interactions, and
within each subclasses if specified.  The graphs present:
\begin{enumerate}
\item Q-Q plots of each covariate to check balance of marginal
  distributions (\texttt{type="QQ"} (default)).  This graph plots
  covariate values that fall in (approximately) the same quantile of
  treated and control distributions.  Control unit quantile values are
  plotted on the x-axis, and treated unit quantile values are plotted
  on the y-axis.  If values fall below the 45 degree line, control
  units generally take lower values of the covariate.  Data points
  that fall exactly on the 45 degree line indicate that the marginal
  distributions are identical.  Discrete covariates that take 5 or
  fewer values are jittered for visibility.  This may be changed by
  setting the option \texttt{discrete.cutoff}.
\item Jitter plots of the propensity score for treated and control
  units (\texttt{type="jitter"}).
\end{enumerate}

\subsubsection{{\tt match.data()}}
\label{subsec:match.data}

To extract the matched data set for subsequent analyses from the
output object (see Section~\ref{subsec:analysis}), we provide the
function {\tt match.data()}.  This is used as follows:
<<results=hide, eval=FALSE>>=
m.data <- match.data(object, group = "all", distance = "distance", weights = "weights", subclass = "subclass")
@
The output of the function {\tt match.data()} is the original data
frame where additional information about matching (i.e., distance
measure as well as resulting weights and subclasses) is added,
restricted to units that were matched.

\paragraph{Inputs}

{\tt match.data()} takes the following inputs:
\begin{enumerate}
\item {\tt object} is the output object from {\tt matchit()}. This is
  a required input.
\item {\tt group} specifies for which matched group the user wants to
  extract the data. Available options are {\tt "all"} (all matched
  units), {\tt "treat"} (matched units in the treatment group), and
  {\tt "control"} (matched units in the control group). The default is
  {\tt "all"}.
\item {\tt distance} specifies the variable name used to store the
  distance measure. The default is {\tt "distance"}.
\item {\tt weights} specifies the variable name used to store the
  resulting weights from matching. The default is {\tt "weights"}. See
  Section~\ref{subsec:weights} for more details on the weights.
\item {\tt subclass} specifies the variable name used to store the
  subclass indicator. The default is {\tt "subclass"}.
\end{enumerate}

\paragraph{Examples}

Here, we present examples for using {\tt match.data()}. Users can run
these commands by typing {\tt demo(match.data)} at the R
prompt. First, we load the Lalonde data,
<<results=hide>>=
data(lalonde)
@
The next line performs nearest neighbor matching based on the
estimated propensity score from the logistic regression,
<<results=hide>>=
m.out1 <- matchit(treat ~ re74 + re75 + age + educ, data = lalonde, method = "nearest", distance = "logit")
@
To obtain matched data, type the following command, 
<<results=hide>>=
m.data1 <- match.data(m.out1)
@
It is easy to summarize the resulting matched data,
<<results=hide>>=
summary(m.data1)
@
To obtain matched data for the treatment or control group, specify the option
{\tt group} as follows,
<<results=hide>>=
m.data2 <- match.data(m.out1, group = "treat")
summary(m.data2)
m.data3 <- match.data(m.out1, group = "control")
summary(m.data3)
@
We can also specify different names for the subclass indicator, the
weight variable, and the estimated distance measure. The following
example first does a subclassification method, obtains the
matched data with specified names for those three variables, and then
print out the names of all variables in the resulting matched data.
<<results=hide>>=
m.out2 <- matchit(treat ~ re74 + re75 + age + educ, data=lalonde, method = "subclass")
m.data4 <- match.data(m.out2, subclass = "block", weights = "w", distance = "pscore")
names(m.data4)
@


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{What's New?}

\begin{itemize}
\item \textbf{2.0-1} (??, 2005): Stable release for R 2.1. Major revisions.
\item \textbf{1.0-2} (August 10, 2005): Stable release for R
  2.1. Minor bug fixes (Thanks to Bart Bonikowski).
\item \textbf{1.0-1} (January 3, 2005): Stable release for R 2.0. The
  first official version of \MatchIt
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Frequently Asked Questions}

\subsection{Can I use a Difference-in-Difference Estimator for Matched
  Data?}

A difference-in-differences (DID) analysis can be easily conducted
with \MatchIt.  If we were interested in the DID matching estimate in
the Lalonde data, we could simply include {\texttt re75} as a
covariate in the preprocessing step.  Then the analysis can be
performed on the change in income from 1975 to 1978: {\tt re78}-{\tt
  re75}.  Time-varying covariates (of which none exist in the Lalonde
data) should of course also be differenced for the DID estimator.
%** we should show how to do this with zelig

\subsection{How Exactly are the Weights Created?}
\label{subsec:weights}

Each type of matching method can be thought of as creating groups of
units with at least one treated unit and at least one control unit in
each.  In exact matching, subclassification, or full matching, these
groups are the subclasses formed, and the number of treated and
control units will vary quite a bit across subclasses.  In nearest
neighbor or optimal matching, the groups are the pairs (or sets) of
treated and control units matched.  In 1:1 nearest neighbor matching
there will be one treated unit and one control unit in each group.  In
2:1 nearest neighbor matching there will be one treated unit and two
control units in each group.  Unmatched units receive a weight of 0.
All matched treated units receive a weight of 1.

The weights for matched control units are formed as follows:
\begin{enumerate}
\item Within each group, each control unit is given a preliminary
  weight of $n_{ti}/n_{ci}$, where $n_{ti}$ and $n_{ci}$ are the
  number of treated and control units in group $i$, respectively.
\item If matching is done with replacement, each control unit's weight
  is added up across the groups in which it was matched.
\item The control group weights are scaled to sum to the number of
  uniquely matched control units.
\end{enumerate}

With subclassification, when the analysis is done separately within
each subclass and then aggregated up across the subclasses, these
weights will generally not be used, but they may be used for full
matching or nearest neighbor matching if the number of control units
matched to each treated unit varies.

\subsection{How Do I Create Observation Names?}
\label{rnames}

Since the diagnostics often make use of the observation names of the
data frame, you may find it helpful to specify observation names for
the data input.  Use the \texttt{row.names} command to achieve this.
For example, to assign the names ``Dan'', ``Kosuke'', ``Liz'' and
``Gary'' to a data frame with the first four observations in the
Lalonde data, type:

<<>>=
test <- lalonde[1:4,]  #taking a lalonde subset
row.names(test) <- c("Dan","Kosuke","Liz","Gary")  #assigning row names
print(test)
@

\subsection{How Do I Ensure Replicability As \MatchIt\ Versions Develop?}
\label{subsec:vercontrol}
As the literature on matching techniques is rapidly evolving,
\MatchIt\ will strive to incorporate new developments. \MatchIt\ is
thereby an evolving program.  Users may be concerned that analysis
written in a particular version may not be compatible with newer
versions of the program.  The primary way to ensure that replication
archives remain valid is to record the version of \MatchIt\ that was
used in the analysis.  Our website maintains binaries of all public
release versions, so that researchers can replicate results exactly
with the appropriate version (for Unix-based platforms, see
\hlink{http://gking.harvard.edu/src/contrib/}{http://gking.harvard.edu/src/contrib/};
for windows, see
\hlink{http://gking.harvard.edu/bin/windows/contrib/}{http://gking.harvard.edu/bin/windows/contrib/}).

In addition, users may find it helpful to install packages with
version control, using the {\tt installWithVers} command with {\tt
install.packages}.  So for example, in the windows R console, users
may download the appropriate version from our website and install the
package with version control by:

\begin{verbatim}
install.packages(choose.files('',filters=Filters[c('zip','All'),]),
                 .libPaths()[1],installWithVers=T,CRAN=NULL)
\end{verbatim}

R CMD INSTALL similarly permits users to specify this version using
the {\tt --with-package-versions} option.  After having specified
version control, different versions of the program may be called as
necessary.  Similar advice may also be appropriate for version control
for R more generally.

\subsection{What Do I Do about Missing Data?}

\MatchIt\ requires complete data sets, with no missing values (other
than potential outcomes of course).  If there are missing values in
the data set, imputation techniques should be used first to fill in
(``impute'') the missing values (both covariates and outcomes), or the
analysis should be done using only complete cases (which we do not in
general recommend).  For imputation software, see Amelia at
(\hlink{http://gking.harvard.edu/stats.shtml}{http://gking.harvard.edu/stats.shtml})
or other programs at
\hlink{http://www.multiple-imputation.com}{http://www.multiple-imputation.com}.
For more information on missing data and imputation methods, see
\cite{KinHonJos01}.

\subsection{Why Preprocessing?}

The purpose of matching is to approximate an experimental template,
where the matching procedure approximates random assignment of
treatment in order to balance covariates between treatment and control
groups.  Separation of the estimation procedure into two steps
simulates the research design of an experiment, where no information
on outcomes is known at the point of experimental design and
randomization.  Much like an experimenter cannot easily rerun an
experiment if the outcome was not satisfactory, the separation of the
balancing process in \MatchIt\ from the analysis process afterwards
helps keep clear the goal of balancing control and treatment groups
and makes it less likely that the user will inadvertently cook the
books in his or her favor.


% see gkbibtex/cvstricks.tex
\clearpage
\bibliographystyle{polisci}
\bibliography{gk,gkpubs}

\end{document}

