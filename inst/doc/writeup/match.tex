\documentclass[11pt,titlepage]{article}
%\usepackage[notref]{showkeys}
\usepackage[reqno]{amsmath}
\usepackage{natbib}
\usepackage{amssymb}
\usepackage{epsfig}
\usepackage{comment}
\usepackage{url}
\usepackage[all]{xy}        
\usepackage[usenames]{color}
\newcommand{\Cb}[1]{\textcolor{ProcessBlue}{#1}}  % blue
\newcommand{\Cr}[1]{\textcolor{Red}{#1}}          % red
\newcommand{\Co}[1]{\textcolor{BurntOrange}{#1}}  % orange
\newcommand{\Cg}[1]{\textcolor{Green}{#1}}        % green
\newcommand{\Cp}[1]{\textcolor{Purple}{#1}}       % purple
\newcommand{\Cbr}[1]{\textcolor{RawSienna}{#1}}    % brown
\usepackage{dcolumn}
\newcolumntype{.}{D{.}{.}{-1}}
\newcolumntype{d}[1]{D{.}{.}{#1}}
\usepackage{threeparttable,booktabs}

% changes for the apsr
%\usepackage{apsr}

% Shortcuts
\renewcommand{\P}{\text{P}}
\newcommand{\MC}{\multicolumn}
\usepackage{calc}
\newcounter{hours}\newcounter{minutes}
\newcommand{\printtime}{%
  \setcounter{hours}{\time/60}%
  \setcounter{minutes}{\time-\value{hours}*60}%
  \thehours :\theminutes}
% \Bpara{x coord}{y coord}{rotation angle in degrees}{height in pt}
\newcommand{\Bpara}[4]{\begin{picture}(0,0)%
    \setlength{\unitlength}{1pt}%
    \put(#1,#2){\rotatebox{#3}{\raisebox{0mm}[0mm][0mm]{%
          \makebox[0mm]{$\left.\rule{0mm}{#4pt}\right\}$}}}}%
    \end{picture}}
%
  \title{Matching Methods for Causal Inference}

\author{Daniel E. Ho\thanks{J.D.\ candidate, Yale Law School, Ph.D.\
    candidate, Department of Government, Harvard
    University. (Center for Basic Research in the Social Sciences, 34
    Kirkland, Cambridge MA 02138, USA;
    \texttt{http://www.people.fas.harvard.edu/\~\,deho},
    \texttt{Deho@Fas.Harvard.Edu}).}
\and %
Kosuke Imai\thanks{Assistant Professor, Department of Politics, Princeton
    University (Corwin Hall 041, Department of Politics, Princeton
    University, Princeton NJ 08544, USA;
    \texttt{http://www.princeton.edu/\~\,kimai},
    \texttt{KImai@Princeton.Edu}).}
\and %
Gary King\thanks{David Florence Professor of Government, Harvard
  University (Center for Basic Research in the Social Sciences, 34
  Kirkland Street, Harvard University, Cambridge MA 02138;
  \texttt{http://GKing.Harvard.Edu}, \texttt{King@Harvard.Edu}, (617)
  495-2027).}
\and %
Elizabeth A. Stuart\thanks{Ph.D.\ Candidate, Department of Statistics, Harvard
  University. (Science Center 702, One Oxford Street, Cambridge, MA
  02138, USA;
  \texttt{http://www.people.fas.harvard.edu/\~\,estuart},
  \texttt{Stuart@Stat.Harvard.Edu}).}}

\date{\today\ (\printtime)} 
\begin{document}\maketitle

\begin{abstract}
Randomized experiments have long  been considered the gold standard
for the estimation of causal effects.  Yet due to 
ethical and practical reasons, it is often infeasible to do randomized
experiments in political science.  We 
discuss the ideas of using matching to replicate randomized
experiments using observational data to draw causal inferences.  The main goal is to obtain 
treated and control groups similar to each other on all of the
observed background covariates.  The framework for 
these methods is the Rubin-Holland model for causal inference, which
has penetrated the biomedical sciences
and to a more limited extent the social sciences.  Yet with a few
unpublished exceptions the framework has not been applied to causal
questions in political science, leaving many causal ``answers'' in the
discipline to rest on unfounded functional form assumptions.  
We provide a summary and guidelines to apply matching
to causal questions in political science, with
applications in international relations, American, and comparative
politics, as well as user-friendly ``MatchIt'' software for R / Splus that
implements these matching methods. 
\end{abstract}

\tableofcontents

\clearpage

\section{Introduction}

A new and exciting statistics literature has emerged in recent years,
building on advances in nonparametric, non-model-based inference, and
focused around diverse generalizations of different types of matching
estimators.  The potential of this literature is enormous, as it offers
the wherewithall for researchers to make much more reliable causal
inferences than has been the case in most of the social sciences.  These
methods make it possible to vastly reduce the necessary functional form
and other assumptions, and to verify empirically rather than assume
unstated but critical modeling assumptions.
                                                                                                                                                             
Unfortunately, this literature has grown into a cacaphony of related but
conflicting techniques, practices, conventions, and rules of thumb.
Valid methods of computing standard errors and confidence intervals are
even more complicated, often not used, and sometimes not available.
Advice and guidelines are lacking or conflicting.
                                                                                                                                                             
In this paper, we attempt to unify this diverse literature for
researchers to make the most productive use of these methods.  Our
simple unifying idea is to think of these new nonparametric techniques
as ways of making the parametric techniques more commonly known and
used in the social sciences (regression, logit, etc.) work better.
This framework thus enables us to add a simple pre-processing step and
let social scientists use whatever models they are already accustomed
to using, rather than requiring them to substitute the methods they
know for one of a set of entirely new and unfamilar methods.  Our
approach therefore has obvious pedagogical and expository advantages,
but the approach also turns out to be useful in bringing intellectual
order and cohesion to this conflicting literature and to suggest
relatively straightforward advice for empirical researchers seeking to
make causal inferences.  When thought of in the way we propose, the
approach also immediately suggests a simple, standardized, and valid
approach to computing standard errors and confidence intervals for any
of the new techniques.
                                                                                                                                                             
In this paper, we describe our unifying approach and all that which leads
from it.  We also describe software we have prepared and are making
available as a companion to this paper.  The software is easy to use and
implements all the ideas discussed herein.
                                                                                                                                                             
\section{Causal inference and potential outcomes}
\subsection{Fundamentals}
Causal effects are inherently a comparison of potential outcomes...generally as the outcome if the treatment of interest
is applied, and the outcome if the treatment of interest is not applied (the ``control'' situation).  e.g., cholesterol level
after two months on a cholesterol-reducing drug compared with cholesterol level after two months on placebo.   Since each unit (e.g., each individual
at a given point in time) either receives or does nto receive the treatment (not both), can think of causal inference as missing data problem where 
we are interested in predicting the missing potential outcomes.  This idea will be discussed in detail in Section \ref{analysis}, which discusses the 
estimation of causal effects.

To estimate causal effects it is important to clearly define what the treatment, units, and potential outcomes are.  What is the treatment of which we are 
estimating the effect?  To whom is the treatment applied or withheld?  And what are the outcomes in which we are interested?  In some situations these
questions are fairly straightforward.  For example, in the cholesterol example, the treatment of interest is a new cholesterol-reducing drug and how it compares
with a placebo.  The units are the individuals who enter the study, at the point in time that they enter the study.  And the potential outcomes of interest
are cholesterol levels two months after treatment assignment.

This definition of causal efects used regardless of how we will learn about the causal effects...whether through a randomized experiment, or through the use of 
observational data.  [Do we need to clarify what we mean by a randomized experiment and observational data?]

\subsection{Assignment mechanism}
The question then is how do we learn about causal effects?  The first key is multiple units...need to observe some individuals who receive the treatment,
and some who receive the control so we can know what happens under both settings.  When multiple units are involved, a key assumption
is that of the Stable Unit Treatment Value Assumption (SUTVA).  There are two components to this: (1) within each treatment group (treatment and control), 
everyone receives the same treatment--there are no versions of the treatments, and (2) no interference between units--one unit's treatment assignment does
not affect the potential outcomes of any other units. 

The final key concept is that of the assignment mechanism, which refers to how the treatments are assigned to units (i.e., determines which potential outcomes
are observed).  This is conveyed by $T$, and we have the identity: ???.  

\subsection{Unbiasedness of causal estimates in randomized experiments}
A key benefit of randomized experiments is that the assignment mechanism is unconfounded; it does not involve the potential outcomes.  
In a completely randomized experiment, the difference in sample means of the potential outcomes is an unbiased estimate of the true treatment effect.  


\subsection{Replicating a hypothetical randomized experiment with observational data}
When we are in a setting with observational data, a key concept is that of trying to replicate a randomized experiment as much as possible.  
Two ways of doing this: find samples that are as similar as possible on all background covariates, and the outcome values are not used in the design.  We thus
will think of carefully designing an observational study--selecting treated and control groups such that they look like they could have arisen from a randomized
experiment.  In that way, any differences in the outcome can be attributed to the treatment itself, not to any pre-existing differences between the groups. 

A key assumption with observational studies is that of unconfounded treatment assignment: that treatment assignment is independent of the potential outcomes
given the observed covariates.  In other words, for two individuals with the same values of observed covariates, if one received treatment and the other control,
then that treatment assignment was random--within groups defined by the covariates, the treated and control groups are only randomly different from one another.
In that way we assume that within blocks defined by the covariates, we have replicated a mini-randomized experiment.  

Since the 1970's, work has developed matching methods to select well-matched samples for comparison, again with this idea of replicating a hypothetical
randomized experiment.  Original work looked at the bias and variance consequences  of choosing matched rather than random samples for follow-up, when
outcome data has not yet been collected on any units and cost constraints prohibit following up the full samples.  Methods extended to situation 
where outcome data already available and interest is in selecting well-matched samples for comparison.  Here we summarize these methods and
present methods for implementing matching with observational data.

\paragraph{Defining units, treatment and outcome.}  In assessing a
  causal effect, the clear definition of treatments and units is crucial.  
  We divide units [variables???]  into two classes: pre-exposure --
  those whose values are determined prior to exposure to the cause;
  post-exposure -- those whose values are determined after exposure to
  the cause.\footnote{Holland, p. 946}  One particularly prevalent issue
  in comparative politics and international relations consists of
  cases where treatment occurs at some time $t$ and persists
  indefinitely.  In Simmons's data, for example, commitment to Article VIII occurs,
  but there is no possibility of ``un-committing.''  In the
  comparative electoral systems data, with few exceptions, a country
  has the same electoral system for long periods of time.  One
  approach taken by researchers has been to define units as
  unit-years, such as country-years or dyad-years.  This, however, violates the
  stability assumptions of matching. 
  [In more traditional econometric terms, the treatment indicator may
  thereby suffer of serial
  correlation\footnote{Duflo, 2003} inducing an artificial causal
  effect.] We suggest redefining the units to be countries (rather than country/years as done by Simmons and others),
which properly reflects the hypothesized assignment mechanism.  In these examples where treatment occurs at time $t$
and persists indefinitely, ``treatment assignment" is not done every year for each state, as implied by the usual
treatment of each country and year as a different unit.  Rather, treatment is applied to each state only once (at time
$t$) and the units modeled should reflect that.  Thus, we recommend [?????] the use of modeling at the country level, 
where
the variables before time $t$ are treated as covariates and the variables after time $t$ are treated as outcomes.  
This idea is explored by Bertrand et al. (2002), and they find that it has good properties.  We will discuss this
method more below.


\subsection{Inference}
\subsubsection{Model Adjustments: The Role of Functional Form Assumptions}
\subsubsection{Matching as way to reduce assumptions/extrapolation}
\subsubsection{Benefits to combining matching and modeling}
                                                                                                                                                             
\section{Overview of Matching}
\subsection{Main idea: find matches that look as similar as possible}
\subsection{Exact matching}
\subsection{Propensity scores as a way to reduce dimensionality}
[This paragraph is from earlier version.]  Similar to exact matching, propensity score matching is simply a means
to obtain a balanced dataset, and the
variance of the sample ATT is the same as in Equation~\ref{VarATT}.
The only difference is the fact that the missing potential outcome
$\hat{Y}_i(0) | T=1$ is now estimated by the matched control unit \emph{via the propensity
score}.  Since the propensity score does not estimate any population
parameter and serves its role purely as a ``balancing score'', it does
not introduce any added uncertainty to the variance of the treatment
effect.\footnote{There is one slight exception to this, namely that
  ties in the propensity score are resolved by a random draw.  This is
  a scenario that is likely to happen when the explanatory covariates
  are largely categorical.  Even in this instance, reporting estimates
  from one draw of matched pairs is correct (akin to drawing a random
  sample from a population), but to avoid potentially ``spurious'' findings, the 
  user might well be advised to impute
  missing potential outcomes several times and combine estimates
  across these datasets via standard multiple imputation rules
  (see \citealt{rubin87}).}  (Note, however, that knowledge of the propensity score might decrease the
variance bound for the ATT, but not the ATE
(\citealt{frolich02,hahn98,HirImbRid02}).)  In fact, this variance
estimate might even be conservative for the sample ATT, providing
over-coverage compared to the variance conditional on the
covariates (\citealt{AbaImbND}).
If on the other hand we are interested in the population ATT, the
variance may be estimated by the bootstrap, or even the Neyman
estimate in Note~\ref{neyman} (\citealt{ImbensNDb}, \citealt[Chapter
6]{ImbRubND}).


                                                                                                                                                             
\section{Details of matching procedures}
\subsection{Estimating propensity scores}
\subsubsection{Logistic regression}
logistic regression usually used.  fit model with treatment assignment on left-hand side and covariates on right-hand side.
Fitted values from regression are the propensity scores.

\subsubsection{Others: CART, GAM, probit}
Other methods can also be used.  [Dan comments here as well?]

\subsection{Nearest neighbor matching}
Generally matching chooses one (or more than one) matches for each unit.  For example, when estimating the average treatment effect
on the treated, choose one (or more than one) control unit for each treated unit.  This is often done using nearest neighbor matching,
which goes through the treated units one by one and finds the best matching control unit.  Variations on and details for this are described in the next few sections.

\subsubsection{Common support: discard}
A key concept is that of matching within regions of common support--estimating causal effects only in area of the covariates where
there are treated and control units.  In essence this is what matching is always attempting to do, but sometimes done more explicitly.
A few ways to do this...

\subsubsection{Order of matching: greedy and optimal matching}
\subsubsection{Matching ratios}
\subsubsection{With or without replacement}
\subsubsection{Caliper matching}
\subsection{Subclassification}
\subsubsection{Full matching}
\subsection{``Special'' variables}
\subsubsection{Exact matching on a few variables}
\subsubsection{Mahalanobis matching within propensity score calipers}
\subsection{Diagnostics}
\subsubsection{Checking for balance}
\subsubsection{Bias statistics}
\subsubsection{Means tests}
\subsubsection{Propensity score model specification}

\section{Analysis}
\subsection{Average treatment effect, average effect on the treated}
\paragraph{Quantity of Interest.} Average treatment effect vs. average
  treatment effect on the treated; limiting inferences to what's
  scientifically estimable. 

\subsection{"Naive" estimates}
\subsubsection{Neyman's estimates of causal effect, variance}
\subsection{Use modeling to repeatedly impute missing potential outcomes}
\subsubsection{Specify standard models in treated and control groups}
\subsubsection{Logistic regression, OLS, etc. (zelig)}
\subsubsection{Contrast with standard OLS (parallel linear regressions)}
\subsection{More information on benefits of combining matching and modeling}
                                                                                                                                                             
\section{Applications}
\subsection{National Supported Work Demonstration}
\subsection{FDA?}
\subsection{Argentinian?}
\subsection{Cross-sectional?}
\subsection{Panel Data?}
                                                                                                                                                             
 
\section{Open research topics}
\subsection{Multi-treatment regimes}
\subsection{Panel Data}
                                                                                                                                                             
\section{Conclusion}


\appendix
\paragraph{Algorithms}
\paragraph{A Sample Matching Algorithm: Optimal Nearest Neighbor One-to-one
Matching with Replacement}
\begin{enumerate}
\item Generate propensity score. \label{assignment}
\item Check balance of pre-treatment covariates.  If an imbalance
  exists, reestimate the assignment model Step~\ref{assignment} by adding
  higher order terms and interactions.  Continue until a obtaining a
  balance in pre-treatment covariates.  
\item Optional: Discard control units with propensity scores below the minimum
  score of treated units (note, other forms of discarding may be suitable).
\item Optional: Re-estimate propensity score.
\item To match units: \label{match}
  \begin{enumerate}
  \item Calculate the absolute difference between propensity
    score of the \emph{non-matched} treated unit with the highest propensity
    score (unit $i$) and all control units. \label{match1}
  \item Match units $i$ and $j$, where:
    \begin{equation}
      | (e_i | T=1)-(e_j | T=0) | < | (e_i | T=1)-(e_k | T=0) |,  \forall k \ne j.  
    \end{equation}
    In the instance multiple control units are
    within the minimum distance, draw randomly to match one of those
    control units. \label{match2}
  \end{enumerate}
\item Continue Steps~\ref{match1}-\ref{match2} for all non-matched
  treated units until all treated units
  are matched. \label{match3}
\item Calculate the average treatment effect on the treated for the
  sample $ATE_s$, where:
  \begin{equation}
    ATE_s=\frac{1}{N_T} \sum_{i=1}^{N_T} \big\{ (Y_i|T=1) - (Y_m|T=0)
    \big \}
  \end{equation}
where $N_T$ represents the number of treated units, $Y_i$ refers to
treated units, and $Y_m$ refers to the control unit matched to $i$. 
\item To estimate the point estimate and variance of $ATE$ bootstrap the donor pool $B$ times
  and repeat (Steps~\ref{match}-\ref{match3}) for each bootstrapped sample, storing
  the estimated average treatment effect $ATE_s$ from each bootstrap. 
\item Lastly, calculate quantities of interest from the distribution
  of bootstrapped $ATE_s$, where the point estimate for the average
  treatment effect on the treated is:
\begin{equation}
    ATE = \frac{1}{B} \sum_{s=1}^{B} ATE_s
\end{equation}
and the variance is:
\begin{equation}
    Var(ATE)= \frac{1}{B-1} \sum_{s=1}^{B} (ATE-ATE_s)^2
\end{equation}
\end{enumerate}

\paragraph{The Subclassification/Regression Adjustment Algorithm for a Binary Outcome
  Variable}
\begin{enumerate}
\item Generate propensity score.
\item Construct 10 blocks defined by the deciles of the propensity
  score for the treated group (where to obtain balance
  in the pre-treatment covariates, (a) split imbalanced blocks further, and/or
  (b) respecify the asssignment model
  to take into account interactions and squares of imbalanced
  covariates).
\item Discard control units with propensity scores below the minimum
  score of treated units.
\item Re-estimate propensity score and regenerate blocks without the
  discarded units (optional)
\item For units within each substratum: \label{sub}
  \begin{enumerate}
  \item{Estimate the logistic model, regressing
      the binary outcome on the propensity scores and the treatment
      indicator.  (If sample sizes permit, this logistic model may
      also be estimated using all covariates.)} \label{sub1}
  \item{Generate a posterior distribution of the parameters from this
      model, drawing 1000 simulated values of $\beta$, where $sim$
      represents each simulated set of parameters.}
  \item{For each substratum and one draw of the parameters $\beta$ from the
      posterior distribution, impute the missing potential outcomes
      $\hat{Y_i}(1)|T_i=0$ and $\hat{Y_i}(0)|T_i=1$ with a logistic regression,
      where:
      \begin{equation}
        (\hat{Y_i}(1)|T_i=0) = \frac{1}{1+exp(-X_i^t \beta)}
      \end{equation}
      and 
      \begin{equation}
        (\hat{Y_i}(0)|T_i=1) = \frac{1}{1+exp(-X_i^c \beta)}
      \end{equation}
      where the superscripts $c$ and $t$ represents the counterfactual
      treatment indicator of control and treatment, respectively.}
  \item{Calculate the treatment effect for all units 
      in the substratum
      \begin{equation}
        TE_{d} = \left( \begin{array}{c}
            (Y(1) | T=1) \\
            (\hat{Y}(1) | T=0)
          \end{array} \right)- 
        \left( \begin{array}{c}
            (\hat{Y}(0) | T=1)\\
            (Y(0) | T=0)
          \end{array} \right)
      \end{equation}
      where $d$ represents the subscript for the decile and $TE_{d}$
      is a vector of treatment effects for all $i$ units in the
      substratum, $(Y(1) | T=1)$ and $(Y(0) | T=0)$ represent vectors
      of observed potential outcomes, and $(\hat{Y}(1) | T=0)$ and
      $(\hat{Y}(0) | T=1)$ represent vectors of imputed missing
      potential outcomes.}
  \item {Calculate the average treatment effect for the substratum
      conditional on the set of simulated parameters $ATE_{d,sim}$:
      \begin{equation}
        ATE_{d,sim}=\frac{1}{n_d} \sum_{i=1}^{n_d}TE_{i,d}
      \end{equation}
      where $n_d$ represents the number of units in the substratum,
      and $TE_{i,d}$ refers to the treatment effect for each unit $i$
      in substratum $d$.} \label{sub2}
  \item{Repeat Steps~\ref{sub1}-\ref{sub2} for all draws of $\beta$.}
  \item {Calculate the average treatment effect for the substratum
      across all simulated parameters $ATE_d$:
      \begin{equation}
        ATE_{d}=\frac{1}{1000} \sum_{sim=1}^{1000} ATE_{d,sim}
      \end{equation}}
  \item{Calculate the variance of $ATE_d$ for that substratum:
      \begin{equation}
        Var(ATE_d)=Var(ATE_{d,sim})
      \end{equation}} \label{sub3}
  \item Finally repeat Steps~\ref{sub1}-\ref{sub3} to generate $ATE_d$
    and $Var(ATE_d)$ for all substrata. 
  \end{enumerate}
\item{Having completed each of the above steps for each substratum,
    calculate the overall average treatment effect ATE:
    \begin{equation}
      ATE=\sum_{d=1}^{10} \Big \{ \big (\frac{n_{d,t}}{N_t} \big ) \big (ATE_d
      \big ) \Big \}
    \end{equation}
    where $n_{d,t}$ represents the number of treated units in each
    substratum $d$ and $N_t$ represents the total number of treated units
    across all substrata.}
\item{Finally, calculate the overall variance of the ATE:
    \begin{equation}
      Var(ATE)=\sum_{d=1}^{10} \Big \{ \big (\frac{n_{d,t}}{N_t} \big )^2 \big (Var(ATE_d)
      \big ) \Big \}.
    \end{equation}}
\end{enumerate}



%\begin{figure}[h]
%  \begin{center}
%    \includegraphics[width=3in,angle=-90]{figs/term_lib}
%  \end{center}
%  \caption{Proportion of civil rights and liberties cases decided
%    liberally}
%\end{figure}

\clearpage
%\singlespacing

\bibliographystyle{pa}
\bibliography{~/gkbibtex/gk,~/gkbibtex/gkpubs}


\end{document}
