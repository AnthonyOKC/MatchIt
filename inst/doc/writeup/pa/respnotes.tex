\documentclass[11pt]{article}
\usepackage{graphicx,latexsym,amssymb,amsmath}
%% === margins ===
\addtolength{\hoffset}{-0.75in} \addtolength{\voffset}{-0.75in}
\addtolength{\textwidth}{1.5in} \addtolength{\textheight}{1.6in}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
  {\bf \Large Point-By-Point Reply to the Reviewers}\\
  ``Matching as Nonparametric Preprocessing for Reducing Model
  Dependence in Parametric Causal Inference,'' {\it Political
  Analysis} Manuscript
\end{center}

We begin by thanking the Reviewers for the careful reading of our
manuscript and many helpful comments.  We believe that we have
addressed all of these suggestions and produced our revised
manuscript. In so doing, we have improved our presentation
significantly. In what follows, we detail the changes we made to our
manuscript in response to the editor's and reviewers' comments.

\paragraph{Reply to Reviewer~1}

p.1, bottom: we don't do Bayesian model averaging or Leamer's extreme
bounds analysis because once you preprocess (well), all the models you
estimate will give roughly the same answers.  So the model dependence
that is the uncertainty intended to be captured by BMA is no longer an
issue.  We have no objection to BMA or EBA but for those you need to
specific a particular class of models which you will average over or
calculate the bounds for.  In our approach, preprocessing should
reduce model dependence for any model in a broad range.

p.2, top.  I think there is only one confusion in the literature
(which i realize after our conversation with Alberto). it comes from
the econometricians assuming as little as possible and statisticians
or applied soc scientists assuming full parametric models.  we can
just clarify this (instead of saying that there is controversy over
how to compute se's) and explain that we are trying to help people who
are ALREADY assuming parametric models by adding preprocessing.

p.2, 2nd para: yes there's a bias-variance tradeoff.  with matching
you discard data that, if you were willing to assume the model was
right, would often produce smaller se's.  that's the intuition the
reviewer wanted. but there are 2 qualifications:  1 is that we aren't
willing to assume the parametric model applies to some areas, and 2 is
that in some cases discarding data can reduce variance.  and most
importantly the 'more data is better' rule only applies when the model
is ``self-efficient'' (Meng) and we rule that out when you don't know
what the model is.

3rd para: are there theorems we don't now reference BUT are relevant
to practical application?  I think we decided this was 'no', but we
should check.  the point we make is that most of the thms are really
irrelevant to practice since they assume things we don't know.  the
``good old MSE'' criteria only make sense if you assume there is no
misspecification. 

bottom, p.2 we have leave fig 1 in, but explain more clearly that it
is a hypothetical example.  i think we can also explain also point in
the blog entry I recently wrote (see at the end of this message; it
hasn't been posted yet) about advantages of other approaches and how
they all often give similar answers when done properly.

last para p.2.  section 6 is already a checklist.

top, p.3. we could define model dependence formally.  in King and
Zeng, we define it as:

``For simplicity in this section, we define \emph{model dependence} at
point $x$ as the difference, or distance, between the predicted
outcome values from any two \emph{plausible} alternative models.  (One
model might be logit and the other probit, or one linear the other
quadratic, etc.)  By ``plausible'' alternative models, we mean models
that fit the data reasonably well and, in particular, they fit about
equally well around either the ``center'' of the data (such as a
multivariate mean or median) or the center of a sufficiently large
cluster of data nearest the counterfactual $x$ of interest. It is easy
to generate model dependence when the model does not even fit the
data, but this is easy to avoid, as many current data analysis
techniques are designed to detect and correct bad fitting models.''

sure, we can change 'the' to 'a'

\paragraph{Reply to Reviewer~2}

1. i think we should be willing to this if the editor would really
like us to, but i think our position should be that it is wrong.
i.e., our whole point is that virtually all regression-type models are
conditional on X, and the se's are computed from that perspective.
the uncertainty is not different whether X is determined by the world,
by some classical experimental design (randomized blocks), by strata
in a survey, or by matching.  the only difference is that only in the
latter case can we optimize: we choose the ``best'' (the optimum)
among all matching solutions.  the only reason for us to consider a
different one is if someone can find a better match.  in that case,
our answers may well change.  but this isn't model uncertainty in the
same way as due to models which CANNOT really be ranked in terms of
which is better (BMA not withstanding).

2. 1-to-n matching is ok with us too.  why did we do 1-to-1 in this
example?  and of course we'll make the data available.

3.  the difference is that in the stat 101 example, the selection is
on Y, whereas in matching if you follow the rules you only select on
X, which can cause no bias.

you can look at Rubin's work as adding observations rather than
deleting some, but you'd still have to ask why he doesn't add them
all.  its the same issue.  why do we delete observations?  because
more observations are only better if the model is self-efficient.
otherwise you just get model dependence and have no real advantage.

4.  same comment as for 3.  cite Imai and Van Dyk.  do any of these
alternative methods move you?

5. so we have to better state the formal but irrelevant thm about
pscores.  anyone have a better way to say this?

6.  we're right about balance tests.  no reason to move here.

\paragraph{Reply to Reviwer~3}

a cranky review.  so we just clarify things a bit more.

authors can keep using their parametric model as they had and they'd
be better off.  of course, we recommend that they also use their
parametric model better, and there's a lot of room for improvement
here.  fair enough, but it doesn't affect us much except for some
wording.

``first to work out the conditions...''  we're right here; the
reviewer found no other citation and neither did we.

I like the Ec Inf section, but we can make it short and make it a FN
perhaps; not sure i think it adds a lot, but maybe we give on things
that aren't central.

'doubly robust'.  i think we need to find a more careful way of making
and appropriately qualifying this claim, but i think we should keep
the phrase.
 
'balance test fallacy':  ok, so we also mention (again!) that we
should verify balance on more than just the first moment.

se's:  right some rare methods don't condition on X.  big deal.  the
clarification i mention above about se's should help here too.

why is this different from 2sls.  ugh.  no reason to change the paper
for this but perhaps we can write something for the reviewer.

exactly what semi-parametric alternatives do social scientists know
well?  

\end{document}
