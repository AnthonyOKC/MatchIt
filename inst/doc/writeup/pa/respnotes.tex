\documentclass[11pt]{article}
\usepackage{graphicx,latexsym,amssymb,amsmath}
%% === margins ===
\addtolength{\hoffset}{-0.75in} \addtolength{\voffset}{-0.75in}
\addtolength{\textwidth}{1.5in} \addtolength{\textheight}{1.6in}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
  {\bf \Large Point-By-Point Reply to the Reviewers}\\
  ``Matching as Nonparametric Preprocessing for Reducing Model
  Dependence in Parametric Causal Inference,'' {\it Political
  Analysis} Manuscript
\end{center}

We begin by thanking the Reviewers for the careful reading of our
manuscript and many helpful comments.  We believe that we have
addressed all of these suggestions and produced our revised
manuscript. In so doing, we have improved our presentation
significantly. In what follows, we detail the changes we made to our
manuscript in response to the editor's and reviewers' comments.

\paragraph{Reply to Reviewer~1}

\begin{enumerate}
\item {\bf Bayesian model averaging and EBA.} In the matching-based
  approach we propose, we are trying to reduce the model uncertainty
  by preprocessing the data. If the matching is done successfully,
  then model uncertainty should be considerably reduced and therefore
  the need for the methods like BMA and EBA will be less. Also, it
  should be noted that matching deals with model uncertainty in the
  specific context of causal inference, whereas BMA and EBA are mainly
  concerned about predictive inference or how well a given model fits
  to the {\it observed} data, as opposed to {\it unobserved potential
    outcomes}.  {\bf Gary, shouldn't we clarify this in the footnote
    we mention BMA and EBA so that we can say it we addressed this
    point in the revision.}

\item {\bf Computing standard errors.} We clarify the issue of how to
  compute the standard errors in the revised manuscript. See the last
  subsection of Section 5. It The standard variance calculation can be
  difficult under the nonparametric settings, but in the context of
  our parametric adjustments, this is straightforward.

\item {\bf Bias-variance trade off.} In the revised manuscript, we
  explicitly discuss the paradoxical advantages of discarding data
  (see Section 5). The basic message is this: discarding the data can
  reduce the variance of the estimator if the model fits the better;
  and hence can reduce the MSE (we already know that the bias goes
  down).  Formally, this is known as the ``self-efficiency'' principle
  in the statistical literature, and the reference is provided in the
  revised manuscript.

\item {\bf Figure 1.} This is meant to be an illustrative rather than
  realistic example. In practice, the detection of model
  misspecification is even more difficult in part due to the
  high-dimensionality of the covariate space.  We noted this point in
  the revised manuscript.

\item {\bf Step-by-step statement.} We did not follow the suggestion
  of providing a ``pseudo-code'' algorithm because we think that
  substantive knowledge researchers have {\it should} be used in the
  process of matching (rather than automating the entire process as
  recommended by some methodologists). But, we tried to state our
  recommendations more clearly in the revised manuscript.

\item {\bf Model dependence.} We formally define model dependence in
  the revised manuscript. See Section 4.3.

\item {\bf Comparison with other approaches.} Our point is that if
  matching is done correctly, then model dependence is reduced and so
  what model you use (whether parametric, semi-parametric, or
  nonparametric) after matching matters little. We clarified this
  point in the revised manuscript.


\item {\bf ``the parametric model.''} We changed ``the'' to `a'
  following the suggestion.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Reply to Reviewer~2}

1. i think we should be willing to this if the editor would really
like us to, but i think our position should be that it is wrong.
i.e., our whole point is that virtually all regression-type models are
conditional on X, and the se's are computed from that perspective.
the uncertainty is not different whether X is determined by the world,
by some classical experimental design (randomized blocks), by strata
in a survey, or by matching.  the only difference is that only in the
latter case can we optimize: we choose the ``best'' (the optimum)
among all matching solutions.  the only reason for us to consider a
different one is if someone can find a better match.  in that case,
our answers may well change.  but this isn't model uncertainty in the
same way as due to models which CANNOT really be ranked in terms of
which is better (BMA not withstanding).

2. 1-to-n matching is ok with us too.  why did we do 1-to-1 in this
example?  and of course we'll make the data available.

3.  the difference is that in the stat 101 example, the selection is
on Y, whereas in matching if you follow the rules you only select on
X, which can cause no bias.

you can look at Rubin's work as adding observations rather than
deleting some, but you'd still have to ask why he doesn't add them
all.  its the same issue.  why do we delete observations?  because
more observations are only better if the model is self-efficient.
otherwise you just get model dependence and have no real advantage.

4.  same comment as for 3.  cite Imai and Van Dyk.  do any of these
alternative methods move you?

5. so we have to better state the formal but irrelevant thm about
pscores.  anyone have a better way to say this?

6.  we're right about balance tests.  no reason to move here.

\paragraph{Reply to Reviwer~3}

a cranky review.  so we just clarify things a bit more.

authors can keep using their parametric model as they had and they'd
be better off.  of course, we recommend that they also use their
parametric model better, and there's a lot of room for improvement
here.  fair enough, but it doesn't affect us much except for some
wording.

``first to work out the conditions...''  we're right here; the
reviewer found no other citation and neither did we.

I like the Ec Inf section, but we can make it short and make it a FN
perhaps; not sure i think it adds a lot, but maybe we give on things
that aren't central.

'doubly robust'.  i think we need to find a more careful way of making
and appropriately qualifying this claim, but i think we should keep
the phrase.
 
'balance test fallacy':  ok, so we also mention (again!) that we
should verify balance on more than just the first moment.

se's:  right some rare methods don't condition on X.  big deal.  the
clarification i mention above about se's should help here too.

why is this different from 2sls.  ugh.  no reason to change the paper
for this but perhaps we can write something for the reviewer.

exactly what semi-parametric alternatives do social scientists know
well?  

\end{document}
