\documentclass[oneside,letterpaper,titlepage]{article}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage[reqno]{amsmath}
\usepackage{amssymb}
\usepackage{verbatim}
\usepackage{epsf}
\usepackage{url}
\usepackage{html}
\usepackage{dcolumn}
\usepackage{fullpage}
\newcolumntype{.}{D{.}{.}{-1}}
\newcolumntype{d}[1]{D{.}{.}{#1}}
%\pagestyle{myheadings}
\htmladdtonavigation{
  \htmladdnormallink{%
    \htmladdimg{http://gking.harvard.edu/pics/home.gif}}
  {http://gking.harvard.edu/}}
\newcommand{\hlink}{\htmladdnormallink}

\bodytext{ BACKGROUND="http://gking.harvard.edu/pics/temple.jpg"}
\setcounter{tocdepth}{3}

\newcommand{\MatchIt}{\textsc{MatchIt}}

\title{\MatchIt: Nonparametric Preprocessing for Parametric Causal
  Inference}

\author{Daniel E. Ho,\thanks{Institute for Quantitative Social Science
    (1727 Cambridge Street, Cambridge MA 02138, USA;
    \texttt{http://people.iq.harvard.edu/~dho/},
    \texttt{daniel.e.ho@gmail.com}).}  \and 
%
  Kosuke Imai,\thanks{Assistant Professor, Department of Politics,
    Princeton University (Corwin Hall 041, Department of Politics,
    Princeton University, Princeton NJ 08544, USA;
    \texttt{http://imai.princeton.edu},
    \texttt{kimai@Princeton.Edu}).}  \and
%
  Gary King,\thanks{David Florence Professor of Government, Harvard
    University (Institute for Quantitative Social Science, 1737
    Cambridge Street, Harvard University, Cambridge MA 02138;
    \texttt{http://GKing.Harvard.Edu}, \texttt{King@Harvard.Edu},
    (617) 495-2027).}  \and
%
Elizabeth A. Stuart\thanks{Researcher, Mathematica Policy Research,
  Inc.\, Ph.D.\, Department of Statistics, Harvard University. (600
  Maryland Ave., SW, Suite 550, Washington, DC 20024, USA;
  \texttt{http://www.mathematica-mpr.com},
  \texttt{EStuart@Mathematica-MPR.com}).}}

\makeindex

\begin{document}
\maketitle

\SweaveOpts{strip.white=true}

\begin{rawhtml}
  <p> [Also available is a downloadable <a
  href="/matchit/docs/matchit.pdf">PDF</a> version of this entire
  document]
\end{rawhtml}

\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\section{Introduction}
\label{sec:intro}

\MatchIt\ implements the suggestions of \citet*{HoImaKin05} for
improving parametric statistical models and reducing model dependence
by preprocessing data with semi-parametric and non-parametric matching
methods.  After preprocessing with \MatchIt, researchers can use
whatever parametric model and software they would have used without
\MatchIt, without other modification, and produce inferences that are
substantially more robust and less sensitive to modeling assumptions.
(In addition, you may wish to use
\hlink{Zelig}{http://gking.harvard.edu/zelig/} \citep{ImaKinLau04} for
subsequent parametric analyses, as it is designed for maximum
convenience in analyzing \MatchIt\ datasets.)  \MatchIt\ reduces the
dependence of causal inferences on commonly made, but hard-to-justify,
statistical modeling assumptions via a wide range of sophisticated
matching methods.  In addition, we have written \MatchIt\ so that
adding new matching methods to the software is as easy for anyone with
the inclination as it is for us.

\subsection{Software Requirements} 
\label{subsec:require}

\MatchIt\ works in conjunction with the R programming language and
statistical software, and will run on any platform where R is
installed (Windows, Unix, or Mac OS X).  R is available free for
download at the Comprehensive R Archive Network (CRAN) at
\hlink{http://cran.r-project.org/}{http://cran.r-project.org/}.
\MatchIt\ has been tested on the most recent version of R.  A good way
to learn R, if you don't know it already, is to learn Zelig (available
at \hlink{http://gking.harvard.edu}{http://gking.harvard.edu}) which
includes a self-contained introduction to R and can be used to analyze
the matched data after running \MatchIt.

\subsection{Installing \MatchIt}
\label{subsec:install}

To install \MatchIt\ for all platforms, type at the R command prompt:
<<results=hide, eval=FALSE>>=
install.packages("MatchIt")
@
and \MatchIt\ will install itself onto your system automatically.
During the installation process you may either decide to keep or
discard the installation files, which will not affect the way
\MatchIt\ runs.  Note that you only need to do this once.  Some users
may also find it helpful to install the package with version control
(see Subsection~\ref{subsec:vercontrol}). 

We recommend that users also install Zelig, Matching, and optmatch by
typing the following commands,
<<results=hide, eval=FALSE>>=
install.packages("Zelig")
install.packages("Matching")
install.packages("optmatch", contriburl = "http://www.stat.lsa.umich.edu/~bbh/optmatch")
@

\subsection{Loading \MatchIt} \label{subsec:load}

As with any R package, you need install \MatchIt\ only once, but you
must load it prior to each use.  You can do this for each R session by
typing
<<results=hide>>=
library(MatchIt) 
@
at the R command prompt.  

Alternatively, you can specify R to load \MatchIt\ automatically at
launch so that you can skip the step of typing {\tt library(MatchIt)}
at the beginning of every R session.  To do this, edit the {\tt
  Rprofile} file located in the R program subdirectory, e.g.
\texttt{C:/R/rw2011/etc/}, for Windows systems or the {\tt .Rprofile}
file located in the home directory for Unix/Linux and Mac OS X
systems.  Using a text editor such as Windows notepad and emacs, add
the following line to the file:
<<results=hide, eval=FALSE>>=
options(defaultPackages = c(getOption("defaultPackages"), "MatchIt"))
@
For this change to take effect, you need to restart R.

\subsection{Updating \MatchIt}

We recommend that you periodically update \MatchIt\ at the R prompt by typing:
<<results=hide, eval=FALSE>>=
update.packages()
library(MatchIt) 
@
which will update all the libraries including \MatchIt\ and load the
new version of \MatchIt.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Statistical Overview}

\MatchIt\ is designed for studies with a dependent variable (or a set
of dependent variables) that is a function of a dichotomous causal (or
``treatment'') variable, with values known as the ``treated'' and
``control'' groups, and a set of ``pretreatment'' covariates, i.e.,
that are causally prior to the administration of the treatment.  (If
you are interested in the causal effect of more than one variable in
your data set, run \MatchIt\ separately for each one; it is unlikely
in any event that any one parametric model will produce valid causal
inferences for more than one treatment variable at a time.)  \MatchIt\
works for experimental data, but is designed mainly for observational
studies where the treatment variable is simply observed rather than
manipulated at will by the investigator.  \MatchIt\ can be used for
other types of causal variables by dichotomizing them, perhaps in
multiple ways \citep[see also][]{ImaDyk04}.

We adopt the same notation as in \citet*{HoImaKin05}. Unless otherwise
noted, let $i$ index the $n$ units in the dataset, $n_1$ denote the
number of treated units, $n_0$ denote the number of control units
(such that $n=n_0+n_1$), and $x_i$ indicate a vector of pretreatment
(or control) variables for unit $i$.  Let $t_i=1$ when unit $i$ is
assigned treatment, and $t_i=0$ when unit $i$ is assigned control.
(The labels ``treatment'' and ``control'' are arbitrary and can be
switched for convenience.)  Denote $y_i(1)$ as the potential outcome
of unit $i$ under treatment --- the value the outcome variable would
take if $t_i$ were equal to 1, whether or not $t_i$ in fact is 0 or 1
-- and $y_i(0)$ the potential outcome of unit $i$ under control ---
the value the outcome variable would take if $t_i$ were equal to 0,
regardless of its value in fact.  The variables $y_i(1)$ and $y_i(0)$
are jointly unobservable, and for each $i$, we observe one
$y_i=t_iy_i(1)+(1-t_i)y_i(0)$, and not the other.

\subsection{Preprocessing via Matching}

The goal of matching is to preprocess the data prior to the parametric
analysis so that the relationship between $t_i$ and $X_i$ is
eliminated or reduced without introducing bias and inefficiency.  This
means that when matching we can select, duplicate, or selectively drop
observations from an existing sample without inducing bias, as long as
we do so using a rule that is a function only of $t_i$ and $X_i$ and
does not depend on the outcome variable $Y_i$.  \MatchIt\ provides,
implements, and evaluates the choice of these rules.  The output of
\MatchIt\ is a new dataset, to substitute for your original, that has
been preprocessed so that $t_i$ and $X_i$ are unrelated or less
related than before.  This implies that the treatment and control
groups have more similar background characteristics, or, formally
$\tilde p(X\mid t=1) \approx \tilde p(X\mid t=0)$, where $\tilde p$
refers to the observed empirical density of the data (think
histogram), rather than a population density.

The simplest way to obtain good matches (as defined above) is to use
one-to-one exact matching, which pairs each treated unit with one
control unit for which the values of $X_i$ are identical.  However,
with many covariates and finite numbers of potential matches, it is
often very difficult to obtain exact matches.  Fortunately, good
matching only requires that the empirical \emph{distribution} of $X$
given $t=0$ match that of $X$ given $t=1$, and so individual (exactly)
matched pairs are not required.  Indeed, many of the other methods
implemented in \MatchIt\ only attempt to balance the overall covariate
distributions, without necessarily finding one-to-one exact matches.

A key point in \citet*{HoImaKin05} is that matching by itself is not a
method of estimation: Every use of matching in the literature involves
an analysis step following the matching procedure, but almost all
analyses use a simple difference in means.  This procedure is
appropriate only if exact matching was conducted.  In almost all other
cases, some adjustment is required, and there is no reason to degrade
your inferences by using an inferior method of analysis even when
improving your inferences via preprocessing.  With \MatchIt, you can
improve your analyses in two ways.  In fact, \MatchIt\ analyses are
doubly robust in that if \emph{either} the matching analysis or the
analysis model is correct (but not necessarily both) your inferences
will be statistically consistent.

\subsection{Checking Balance}
\label{subsec:balance-sum}

The goal of matching is to simulate an aspect of a randomized
experiment in terms of finding units that look as if they could have
been randomly assigned to treatment or control status.  When this is
the case, we break the link between treatment variable and the
pretreatment controls, which makes the parametric form of the analysis
model less relevant or irrelevant entirely.  To break this link, we
need the distribution of covariates to be the same within the matched
treated and matched control groups. 

A crucial part of any matching procedure is, therefore, to assess how
close the (empirical) covariate distributions are in the two groups,
which is known as ``balance.''  Because the outcome variable is not
used in the matching procedure, a variety of matching methods can be
assessed, and the matching procedure that leads to the best balance is
chosen.  \MatchIt\ provides a number of ways to assess the balance of
covariates after matching, including numerical summaries such as the
standardized bias (difference in means divided by the treated group
standard deviation) and graphical summaries such as quantile-quantile
plots that compare the empirical distributions of each covariate.
These diagnostics can be done on all the covariates that are included
in the matching procedure, as well as on other covariates on which
close matches are desired.

\subsection{Conducting Analyses after Matching}

The most common way that parametric analyses are used to compute
quantities of interest is by holding constant some explanatory
variables, changing others, and computing predicted or expected values
and taking the difference or ratio.  In the case of causal inference,
this would mean looking at the effect on the expected value of the
outcome variable when changing $T$ from 0 to 1, while holding constant
the pretreatment control variables $X$ at their means or medians.
This, and indeed any other standard procedure, would be a perfectly
reasonable way to proceed with analysis after matching.

Another increasingly popular way to proceed with analysis after
\MatchIt\ is to compute the \emph{average treatment effect on the
  treated}.  For example, for the treated group, the potential
outcomes under control, $Y_i(0)$, are missing, whereas the outcomes
under treatment, $Y_i(1)$, are observed, and the goal of the analysis
is to impute the missing outcomes, $Y_i(0)$ in observations where
$T_i=1$.  We do this via simulation using a parametric statistical
model (as described below).  Once those potential outcomes are imputed
from the model, the estimate of individual $i$'s treatment effect is
$Y_i(1)-\widehat{Y}_i(0)$ where $\widehat{Y}_i(0)$ is a Monte Carlo
estimate of the average missing potential outcome for unit $i$ (i.e.,
the average of simulated values of the dependent variable for unit $i$
under the counterfactual condition where $T_i=0$).  The in-sample
average treatment effect for the treated individuals can then be
obtained by averaging this difference over all observations $i$ where
in fact $T_i=1$.  (A similar procedure can also be used to estimate
various other quantities of interest such as the average treatment
effect for all observations.)  An advantage of this simulation
approach is that the uncertainty estimates such as standard errors and
confidence intervals are obtained easily by the usual rules in fitting
the parametric model.

The imputation from the model can be done in at least two ways.
Recall that the model is used to impute \emph{the value that the
  outcome variable would take among the treated units if those treated
  units were actually controls}.  Thus, one reasonable approach would
be to fit a model to the whole set of matched data and create
simulated predicted values of the dependent variable for the treated
units with $T_i$ switched counterfactually from 1 to 0.  An
alternative approach would be to fit a model without $T$ by using only
the outcomes of the matched control units (i.e., using only
observations where $T_i=0$).  Then, given this fitted model, the
missing outcomes $Y_i(0)$ are imputed for the matched treated units by
using the values of the explanatory variables for the treated units.
The first approach will usually have lower variance, since all
observations are used, and the second may have less bias, since no
assumption of constant parameters is needed.  See \citet*{HoImaKin05}
for more details.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{User's Guide to \MatchIt}
\label{methods}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Example Data: National Supported Work Demonstration}
\label{subsec:lalonde}

For a running example, we use data from the job training program
analyzed in \citet{lalonde86} and \citet{DehWah99}. \MatchIt\ includes
a subsample of the original data consisting of the National Supported
Work Demonstration (NSW) treated group and the comparison sample from
the Population Survey of Income Dynamics (PSID).\footnote{This data
set, \texttt{lalonde}, was created using NSWRE74$\_$TREATED.TXT and
CPS3$\_$CONTROLS.TXT from
http://www.columbia.edu/$\sim$rd247/nswdata.}  The variables in this
dataset are described in Table~\ref{dwvars}.  One causal effect of
interest is the impact of participation in the job training program,
\texttt{treat == 1}, on real earnings in 1978, \texttt{re78}, for
those individuals that participated in the program.  The average
treatment effect on the treated (ATT) is defined as,
\begin{align}
  \label{att}
  \text{ATT} & = \frac{1}{\sum_{i=1}^n t_i}\sum_{i:t_i=1} E[Y_i(1) - Y_i(0)],
\end{align}
where $Y_i(1)$ represents the potential outcome under the treatment of
the job program, and $Y_i(0)$ is the potential outcome under control.
Note that the first term inside the expectation (the right hand side
of Equation~\ref{att}) is \emph{observed}, whereas the second term is
the \emph{unobserved} counterfactual of real earnings if participants
had not participated.  The nature of causal inference is that one of
the two terms in the difference will always be unobserved.
\begin{table}[h]
\centering
\begin{tabular}{lp{3in}}
  \hline 
  \multicolumn{1}{l}{Variable name} & \multicolumn{1}{c}{Description} \\
  \hline
  \multicolumn{2}{l}{\textbf{Outcome variable ($Y$)}} \\ 
  \texttt{re78} & Real earnings (1978) \\ \\
  \multicolumn{2}{l}{\textbf{Treatment variable ($T$)}} \\
  \texttt{treat} & Treated in job training program from March 1975-June
  1977 (1 if treated, 0 if not treated)
  \\ \\
  \multicolumn{2}{l}{\textbf{Pre-treatment covariates ($X$)}} \\
  \texttt{age} & Age\\
  \texttt{educ} & Years of education \\
  \texttt{black} & Race black (1 if black, 0 otherwise) \\
  \texttt{hispan} & Race hispanic  (1 if Hispanic, 0 otherwise) \\
  \texttt{married} & Marital status (1 if married, 0 otherwise) \\
  \texttt{nodegree} & High school degree (1 if no degree, 0 otherwise)\\
  \texttt{re74} & Real earnings (1974) \\
  \texttt{re75} & Real earnings (1975) \\ 
  \hline
\end{tabular}\label{lalonde}
\caption{Description of Lalonde data \label{dwvars}}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Preprocessing via Matching}
\label{subsec:matching}

The main command \texttt{matchit()} implements a variety of matching
procedures.  A general syntax is given by
<<results=hide, eval=FALSE>>=
m.out <- matchit(treat ~ x1 + x2, data = mydata)
@
where {\tt treat} is the dichotomous treatment variable, and {\tt x1}
and {\tt x2} are pre-treatment covariates, all of which are contained
in the data frame {\tt mydata}.  This command creates the
\MatchIt\, object called \texttt{m.out}.  A quick summary of the
matching procedure can be printed on the screen by typing
<<results=hide, eval=FALSE>>=
m.out
@
or
<<results=hide, eval=FALSE>>=
print(m.out)
@
Examples of various matching procedures are given for the reminder of
this section, and Section~\ref{subsec:inputs} lists all possible
specifications of {\tt matchit()}.

\subsubsection{Exact Matching}
\label{subsubsec:exact}

The simplest version of matching is exact.  This technique matches
\emph{each} treated unit to \emph{all} possible control units with
exactly the same value on all the covariates, forming subclasses such
that within each subclass all units (treatment and control) have the
same covariate values.  Exact restrictions on a subset of covariates
can also be specified in nearest neighbor matching (see
Section~\ref{subsubsec:nearest}).

The following example script can be run by typing {\tt demo(exact)} at
the R prompt:
<<>>=
library(MatchIt)
data(lalonde)
m.out <- matchit(treat ~ educ + black + hispan, data = lalonde, method = "exact")
@
The object \texttt{m.out} contains all the information on the matched
units.  \MatchIt\ creates all possible subclasses based on unique
values of the covariates in the right hand side of the formula; within
each subclass, all units have the same covariate values.  To obtain
a short summary about the matching procedure, type
<<>>=
m.out
@
The printout includes the matched call and shows that
\Sexpr{sum(m.out$weights[m.out$treat==1]!=0)} treatment units were
exactly matched to \Sexpr{sum(m.out$weights[m.out$treat==0]!=0)}
control units on race and education. There was
\Sexpr{sum(m.out$weights[m.out$treat==1]==0)} treated unit and
\Sexpr{sum(m.out$weights[m.out$treat==0]==0)} control units that were
not matched, and therefore were excluded from the matched data set.
See
Sections~\ref{subsubsec:inputs-all}~and~\ref{subsubsec:inputs-exact}
for a complete list of input options for exact matching.  Now, you may
also want to proceed to Section~\ref{subsec:balance} to learn about
how the {\tt summary()} command can be used with exact matching.

\subsubsection{Subclassification}
\label{subsubsec:subclass}

When there are many covariates 
on which matches are desired (or some covariates can take a large
number of values), finding sufficient
exact matches will often be impossible.  In that case,
subclassification is sometimes desirable. Various subclassification
schemes exist, including the one based on a scalar distance measure
such as the propensity score estimated using the \texttt{distance}
option (see Section~\ref{subsubsec:inputs-all}).  Subclassification
will form subclasses based on this distance measure.  Within each
subclass, the distribution of covariates in the treatment and control
groups should be similar.

Subclassification is implemented in \MatchIt\ using \texttt{method =
  "subclass"}.  See also the sections on full matching (Section
\ref{subsubsec:full}) and nearest-neighbor matching (Section
\ref{subsubsec:nearest}), which provide additional ways of performing
subclassification.  The following example script can be run by typing
{\tt demo(subclass)} at the R prompt:
<<>>=
m.out <-  matchit(treat ~ re74 + re75 + educ + black + hispan + age, data = lalonde, method = "subclass")
m.out
@
The above syntax forms forms 6 subclasses, which is the default number
of subclasses, based on a distance measure estimated using logistic
regression.  By default, each subclass will have approximately the
same number of treated units.  See
Sections~\ref{subsubsec:inputs-all}~and~\ref{subsubsec:inputs-subclass}
for a complete list of input options for subclassification.

Subclassification may also be used in conjunction with nearest
neighbor matching described below in
Subsection~\ref{subsubsec:nearest}, by leaving the default of
\texttt{method = "nearest"} but adding the option \texttt{subclass}.
When you choose this command, \MatchIt\ matches in the same way, but
after the nearest neighbor matches are chosen it places them into
subclasses, and adds a variable to the output object with the subclass
numbers.

\subsubsection{Nearest Neighbor Matching}
\label{subsubsec:nearest}

Nearest neighbor matching selects the $r$ best control matches for
each individual in the treatment group (excluding those discarded
using the \texttt{discard}) option (by default, $r=1$).  The matching
is done using a distance measure specified by the {\tt distance}
option. Matches are chosen for each treated unit one at a time, and at
each matching step we choose the control unit that is not yet matched
but is closest to the treated unit on the distance measure.  There are
many variations on nearest neighbor matching, which are described in
further detail in
Sections~\ref{subsubsec:inputs-all}~and~\ref{subsubsec:inputs-nearest}.

Nearest neighbor matching is implemented in \MatchIt\ using the
\texttt{method="nearest"} option.  The following example script can be
run by typing {\tt demo(nearest)} at the R prompt.

To conduct propensity score matching with pre-treatment covariates
composed of real earnings in 1974 and 1975, education, race, and age:
<<>>=
m.out <- matchit(treat ~ re74 + re75 + educ + black + hispan + age, data = lalonde, method = "nearest")
@
You may again check basic statistics of the \MatchIt\ object by the
\texttt{print} command:
<<>>=
m.out
@ 
We see that 185 control units were matched to the 185 treated units
(a one-to-one match).  

\paragraph{Additional Examples}

Here, we illustrate various options of nearest neighbor matching by
providing additional examples based on the Lalonde data. Users should
refer to
Sections~\ref{subsubsec:inputs-all}~and~\ref{subsubsec:inputs-nearest}
for a complete list of options for nearest neighbor matching.

\begin{enumerate}

\item Nearest neighbor matching on propensity score estimated using
  logistic regression where 2 matches are chosen for each treated unit.
<<results=hide>>=
m.out1 <- matchit(treat ~ re74 + re75 + age + educ, data = lalonde, method = "nearest", distance = "logit", ratio=2)
@

\item Mahalanobis matching on {\tt re74} and {\tt re75}.
<<results=hide>>=
m.out <- matchit(treat ~ re74+re75, data=lalonde, method="nearest", distance="mahalanobis")
@

\item Mahalanobis matching on {\tt re74} and {\tt re75} within nearest
  neighbor matching on distance measure (propensity score), with restriction of exact
  matches on {\tt married}.
<<results=hide>>=
m.out2 <- matchit(treat ~ re74 + re75 + age + educ, data = lalonde, method = "nearest", distance = "logit", mahvars=c("re74", "re75"), exact=c("married"), caliper=.25)
@

\item Nearest neighbor matching after discarding all units outside of
  the common support of the estimated distance measure.
<<results=hide>>=
m.out3 <- matchit(treat ~ re74 + re75 + age + educ, data = lalonde, method = "nearest", distance = "logit", discard= "both")
@

\item Nearest neighbor matching with replacement where two control
  units are matched with one treated unit.
<<results=hide>>=
m.out4 <- matchit(treat ~ re74 + re75 + age + educ, data = lalonde, method = "nearest", distance = "logit", replace = TRUE, ratio = 2)
@

\item Nearest neighbor matching followed by formation of 5 subclasses
<<results=hide>>=
m.out5 <- matchit(treat ~ re74 + re75 + age + educ, data = lalonde, method = "nearest", distance = "logit", subclass=5)
@
\end{enumerate}


\subsubsection{Optimal Matching}
\label{subsubsec:optimal}

The default nearest neighbor matching method in \MatchIt\ is
``greedy'' matching, where the closest control match for each treated
unit is chosen one at a time, without trying to minimize a global
distance measure.  Another method, ``optimal'' matching, finds the
matched samples with the smallest average absolute distance between
each matched pair.  With large control pools, greedy and optimal
matching may lead to very similar (or the same) sets of matches;
\citet{GuRos93} find that greedy and optimal matching generally choose
the same sets of controls for the overall matched samples, but that
optimal matching does a better job of minimizing the distance within
each pair.  In addition, optimal matching can be helpful when there
are not many appropriate control matches for the treated units.  See
\cite{GuRos93} or \cite{Rosenbaum02} for more information on optimal
matching.
Sections~\ref{subsubsec:inputs-all}~and~\ref{subsubsec:inputs-optimal}
give a complete list of optional inputs for optimal matching.

Optimal matching is performed with \MatchIt\ by setting \texttt{method
  = "optimal"}.  We use an add-on package called \texttt{optmatch}
\citep{Hansen04}, which will be automatically installed when optimal
matching is performed (if it is not installed already). The package can
also be installed separately by typing at the R command prompt,
<<results=hide,eval=FALSE>>=
  install.packages("optmatch", contriburl = "http://www.stat.lsa.umich.edu/~bbh/optmatch") 
@ 

For more information about the package, see
\hlink{http://www.stat.lsa.umich.edu/\~{}bbh/optmatch.html}{http://www.stat.lsa.umich.edu/\~bbh/optmatch.html}.

The following example script (optimal ratio matching based on the
propensity score from the logistic regression) can be run by typing
{\tt demo(optimal)} at the R prompt.
<<>>=
m.out <- matchit(treat ~ re74 + re75 + age + educ, data = lalonde, method = "optimal", distance = "logit", ratio = 2)
m.out
@
The short summary shows that for each treated unit, two control units
are matched through the optimal matching procedure.

\subsubsection{Full Matching}
\label{subsubsec:full}

Full matching is a a particular type of subclassification that uses
all treated and control units \citep{Rosenbaum02, Hansen04}.  A fully
matched sample is composed of matched sets, where each matched set
contains one treated unit and one or more controls (or one control
unit and one or more treated units).  The only units not placed into a
subclass will be those discarded (if a \texttt{discard} option was
specified) because they are outside the range of common support.  Full
matching is optimal in terms of minimizing a weighted average of the
estimated distance measure between each treated subject and each
control subject within each subclass.  See
Sections~\ref{subsubsec:inputs-all}~and~\ref{subsubsec:inputs-full}
for a complete list of optional inputs for full matching.

Full matching can be performed with \MatchIt\ by setting
\texttt{method = "full"}.  We use an add-on package called
\texttt{optmatch} \citep{Hansen04}, which will be automatically
installed when optimal matching is performed (if it is not installed
already). The package can also be installed separately by typing at
the R command prompt,
<<results=hide,eval=FALSE>>=
install.packages("optmatch", contriburl = "http://www.stat.lsa.umich.edu/~bbh/optmatch") 
@ 
For more information
about the package, see
\hlink{http://www.stat.lsa.umich.edu/\~{}bbh/optmatch.html}{http://www.stat.lsa.umich.edu/\~bbh/optmatch.html}.

The following example script can be run by typing {\tt demo(full)} at
the R prompt.  We first load the Lalonde data, conduct full matching
(using the propensity score based on logistic regression), and then
print a short summary.
<<>>=
m.out <- matchit(treat ~ age + educ + black + hispan + married + nodegree + re74 + re75, data = lalonde, method = "full", distance = "logit")
m.out
@
We see that the matching has utilized all units (the treated and
control group sample sizes are the same for the full and matched
samples). 

\subsubsection{Genetic Matching}
\label{subsub:genetic}

Genetic matching is a method that automates the process of finding an
optimal balance \citep{DiaSek05}. The idea is to use a genetic search
algorithm and find a set of weights for each covariate such that the
optimal balance is achieved after matching. The procedure is
implemented in {\tt Matching} package \citep{Sekhon04}. As is
currently implemented, matching is done with replacement using the
matching method of \citet{AbaImb04} and balance is determined by the
two univariate tests; paired t-tests for dichotomous variables and an
Kolmogorov-Smirnov test for multinomial and continuous variables.  See
Sections~\ref{subsubsec:inputs-all}~and~\ref{subsubsec:inputs-genetic}
for a complete list of optional inputs for genetic matching.

Genetic matching can be performed with \MatchIt\ by setting
\texttt{method = "genetic"}.  We use an add-on package called
\texttt{Matching} \citep{Sekhon04}, which will be automatically
installed (if it is not installed already). The package can
also be installed separately by typing at the R command prompt,
<<results=hide,eval=FALSE>>=
install.packages("Matching") 
@ 
For more information about the package, see
\hlink{http://sekhon.polisci.berkeley.edu/matching/}{http://sekhon.polisci.berkeley.edu/matching/}

The following example script can be run by typing {\tt demo(genetic)}
at the R prompt.  We first load the Lalonde data, conduct genetic
matching (using the estimated propensity score based on logistic
regression as one of the covariate), and then print a short summary.
<<results=hide>>=
m.out <- matchit(treat ~ age + educ + black + hispan + married + nodegree + re74 + re75, data = lalonde, method = "genetic", distance = "logit")
@
<<>>=
m.out
@
We see that the matching is done with replacement and only 90 control
units are included for a matched sample.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Checking Balance}
\label{subsec:balance}

In \MatchIt, there are two ways to check balance after any matching
procedure: numerical and graphical summaries. Both methods are based
on the same idea summarized in Section~\ref{subsec:balance-sum} and
fully described in \citet*{HoImaKin05}. Given the \MatchIt\ output
object {\tt m.out}, one can use the following commands,
\begin{enumerate}
\item \texttt{summary(m.out)} gives numerical summaries of the
  resulting balance of the covariates.
  
\item \texttt{plot(m.out)} gives graphical summaries to assess the balance
  of the covariates.
\end{enumerate}
Below, we give three examples (exact matching, nearest neighbor
matching, and subclassification) to illustrate the use of these two
functions. The same two commands can be used for all other matching
procedures, and they will give similar outputs. See
Section~\ref{subsec:outputs} for more details.

\subsubsection{Example 1: Exact matching}
\label{subsubsec:balanceexact}

Using the example of exact matching from
  Section~\ref{subsubsec:exact}, we obtain more information on the
  matching using the {\tt summary()} command.  To also show the
  covariates values in each subclass, we use the \texttt{covariates =
    TRUE} option:
<<>>=
m.out <- matchit(treat ~ educ + black + hispan, data = lalonde, method = "exact")
summary(m.out, covariates = TRUE)
@
\MatchIt\ has created 25 subclasses where the values of the race and
education covariates are equal.  The resulting \MatchIt\ object
includes \texttt{weights} and \texttt{subclass}, which can be used to
identify which units were put into the same subclass (See
Sections~\ref{subsec:analysis}~and~\ref{subsec:match.data} for the
{\tt match.data()} command which creates the matched data set with
these identifying variables).  Units that did not have the same
covariate values as anyone in the other treatment group have
\texttt{subclass = NA}.  For example, we can use the {\tt subclass}
component of {\tt m.out} to identify which units are in each subclass
and to verify their covariate values.  To see the ID numbers of the
first 5 units in subclass 1, in which all subjects are black and have
11 years of education (``NSW'' refers to the National Supported Work
Demonstration participants):
<<>>=
row.names(m.out$X)[m.out$subclass==1][1:5]
@
We can also confirm the covariate values of the units in each
subclass.  For example, to see the covariate values of the first 5
units in subclass 1 (``PSID'' refers to individuals in the Panel
Survey of Income Dynamics):
<<>>=
m.out$X[m.out$subclass==1,][1:5,]
@

\subsubsection{Example 2: Nearest neighbor matching}
\label{subsubsec:balancenearest}
For all other types of matching, the \texttt{summary()} command
  first gives measures of the balance between the treated and control
  groups in the full (original) data set, and then the same measures
  of balance in the matched data set.  If the matching worked well,
  the measures of balance should be smaller in the matched data set as
  compared with the full data set.
  
  To illustrate this we use the example of nearest neighbor matching
  from Section \ref{subsubsec:nearest}:
<<>>=
m.out <- matchit(treat ~ re74 + re75 + educ + black + hispan + age, data = lalonde, method = "nearest")
summary(m.out)
@
The \texttt{summary()} command provides simple statistics of the
propensity score and the covariates used in the matching for the full
and matched samples, including means, standardized bias, and
Quantile-Quantile (Q-Q) plot statistics.  These are used to assess
whether there was a reduction in bias in the covariates. In addition,
the \texttt{summary()} command will report (a) the matched call, (b)
how many units were matched, unmatched, or discarded due to the
\texttt{discard} option (described below), and (c) the percent
improvement in balance for each of the balance measures, defined as
$100((|a|-|b|)/|a|)$, where $a$ is the balance before and $b$ is the
balance after matching.

For each set of units (original and matched data sets), the following
statistics are provided: 
\begin{itemize}
\item ``Means Treated'' and ``Means Control'' show the weighted means in the treated and control groups
\item ``Treated SD'' is the standard deviation of the covariate in the set
of treated units
\item ``Std. Bias'' is the difference in means in the
treated and control groups, divided by the ``Treated SD'' calculated
using all treated units.  The same standard deviation is used for
calculating the standardized bias in the original and the matched data
sets so that the success of the matching at reducing bias in the
covariate means can be easily assessed; standardizing by the same
quantity puts the two differences in means on the same scale.  Good
matches will generally have standardized biases less than
approximately 0.25; values greater than that imply that the groups
have means that are more than a quarter of a standard deviation apart.
\item The final three columns of the summary output give summary statistics
of a Q-Q plot (see below for more information on these plots). Those
columns give the median, mean, and maximum orthogonal deviations from
the 45-degree line of the Q-Q plot.  If the empirical distributions of
the two groups (treated and control) were exactly the same, all points
would lie on the 45-degree line and thus all of these distances would
be 0.  Values greater than 0 indicate deviations between the groups in
some part of the empirical distributions.  The plots themselves,
described below, can provide further insight into which part of the
covariate distribution has differences between the two groups.
\end{itemize}

\paragraph{Balance in this example}

In this example of nearest neighbor matching, we see that the matching
has reduced the bias in the propensity score from 1.79 to 0.95 and has
reduced the bias in some of the covariates (e.g., 1974 and 1975
income).  Job training participants on average earned roughly \$3,524
less in 1974 and \$934 less in 1975 than non-participants, in the full
sample.  In the matched sample, the earnings difference is reduced to
\$371 in 1974 and \$428 in 1975.  This one-to-one matching algorithm
has thus chosen 185 control individuals who are similar to the treated
group in 1974 income and 1975 income, which is summarized by the
$89.5$ and $54.2$ percent balance improvement in these covariates.
However there are still fairly large differences on some of the
covariates, such as the race variables.  In this situation, if close
matches on the race variables are desired, it may make sense to try
Mahalanobis or exact matching on the race variables in addition to the
propensity score matching.  The large remaining bias in the propensity
score (0.95 standard deviations) also indicates that it may be
desirable to do subclassification instead of or in addition to the
matching, as described below.

\paragraph{Additional options}

Two options to the \texttt{summary()} command can also help with
assessing balance and respecifying the propensity score model, as
necessary.  First, the {\tt interactions = TRUE} option with {\tt
  summary()} shows the balance of all squares and interactions of the
covariates used in the matching procedure.  Large differences in
higher order interactions usually are a good indication that the
assignment model needs to be respecified.  Similarly, the {\tt
  addlvariables} option with {\tt summary()} will provide balance
measures on additional variables not included in the original matching
procedure.  If a variable (or interaction of variables) not included
in the original distance measure has large imbalances in the matched
groups, including that variable in the next model specification may
improve the resulting balance on that variable.  \cite{DehWah99}
provides a detailed example of a propensity score specification
algorithm.  Because the outcome variable is not used in the matching
procedure, a variety of matching methods can be tried, and the one
that leads to the best resulting balance chosen.

\paragraph{Examining balance graphically}

We can also examine the balance graphically using the \texttt{plot()}
command, which provides two types of plots: jitter plots of the
distance measure, and Q-Q plots of each covariate.
Figures~\ref{diagqqnn} and~\ref{diagjitternn} display these two sample
plots.  In the jitter plot, you may identify units by observation name
by clicking the first mouse button near the units.
<<results=hide,eval=FALSE>>=
plot(m.out)
plot(m.out, type="jitter")
@

\begin{figure}[tbp]
  \begin{center}
%<<fig=TRUE, width=8, height=5, prefix.string=figs/docs, echo=FALSE>>=
%plot(m.out, interactive=FALSE)
%@
    \includegraphics[width=3in, height=3in]{figs/qqplotnn}
    \includegraphics[width=3in, height=3in]{figs/qqplotnn2} 
    \hfill
    \caption{Sample diagnostic QQ plots: Nearest Neighbor matching
      with the \MatchIt\ call \texttt{matchit(treat ~ re74 + re75 + educ
        + black + hispan + age, data=lalonde, method="nearest")}.}
    \label{diagqqnn}
  \end{center}
\end{figure}

\begin{figure}[tbp]
  \begin{center}
<<fig=TRUE, width=8, height=5, prefix.string=figs/docs, echo=FALSE>>=
plot(m.out, type="jitter", interactive=FALSE)
@
%    \includegraphics[scale=0.5]{figs/jitterplotnn}
    \hfill
    \caption{Sample diagnostic jitter plot: Nearest Neighbor matching
      with the \MatchIt\ call \texttt{matchit(treat ~ re74 + re75 +
        educ + black + hispan + age, data=lalonde, method="nearest")}.
      Matched units shown in black, unmatched units shown in grey.}
    \label{diagjitternn}
  \end{center}
\end{figure}

The balance of the individual covariates is shown in the Q-Q plots.
If the empirical distributions are the same in the treated and control
groups, the points would all lie on the 45 degree line.  Deviations
from the 45 degree line indicate differences in the empirical
distribution.  The jitter plot shows the overall distribution of
propensity scores in the treated and control groups.  In the jitter
plot, the size of each diamond is proportional to the weight given to
that unit; matched units are in black while unmatched units are in
grey.

Examining these graphs, we see that the matched samples are fairly
well matched on the propensity score and the income variables, but
that there are some remaining imbalances in the race and age
variables, as was also seen using the \texttt{summary()} command.

\subsubsection{Example 3: Subclassification}
\label{subsubsec:balancesubclass}
Now for subclassification, using the example from
  Section~\ref{subsubsec:subclass}, we check the balance of covariates
  using the \texttt{summary()} and \texttt{plot()} commands.
<<>>=
m.out <-  matchit(treat ~ re74 + re75 + educ + black + hispan + age, data = lalonde, method = "subclass")
summary(m.out)
@
The \texttt{summary()} output for subclassification is the same as that
for nearest neighbor matching, except that the balance statistics are
shown separately for each subclass, and the overall balance in the
matched samples is calculated by aggregating across the subclasses,
where each subclass is weighted by the number of units in the
subclass.  Consistent with the calculations for the full and matched
samples, the standardized bias within each subclass is also calculated
using the standard deviation of the full treated group, again so that
the differences in means are all scaled by the same amount and not
affected by changes in sample sizes.

\paragraph{Balance in this example}

In this example, the bias between the groups within each subclass is
generally small, with the exception of Subclass 1, which has a large
number of control units with small propensity scores.  The percent
balance improvement also indicates that the subclassification has been
successful at forming subclasses within which the distribution of
covariates is more similar than in the full data set.  In particular,
80 to 90 percent reduction in the standardized bias was achieved in 4
of the 6 covariates through subclassification; little bias reduction
was achieved on the education variable, which had very small bias to
start (standardized bias of only 0.055 in the full data set).  For
this example, it appears as though subclassification has been able to
form better matched samples than the simple 1-1 nearest neighbor
matching method described above.

\paragraph{Examining the balance graphically}

We can also examine the balance graphically.  Figures~\ref{diagqqsub}
and \ref{diagjittersub} display two sample diagnostic plots.  With
subclassification, separate Q-Q plots are printed for each subclass;
for each, the graphs shown in the left-hand column are those for the
full data set.  The jitter plot is the same as that for nearest
neighbor matching, with the addition of vertical lines indicating the
subclass cut-points.
<<results=hide>>=
m.out <- matchit(treat ~ re74 + re75 + educ + black + hispan + age, data = lalonde, method = "subclass")
@
<<results=hide, eval=FALSE>>=
plot(m.out)
plot(m.out, type="jitter")
@

\begin{figure}[tbp]
  \begin{center}
%<<fig=TRUE, width=8, height=5, prefix.string=figs/docs, echo=FALSE>>=
%plot(m.out, interactive=FALSE)
%@
    \includegraphics[width=3in, height=3in]{figs/qqplotsub}
    \includegraphics[width=3in, height=3in]{figs/qqplotsub2}
    \hfill
    \caption{Sample diagnostic QQ plots: Subclassification with
      \MatchIt\ call \texttt{matchit(treat ~ re74 + re75 + educ +
        black + hispan + age, data = lalonde, method = "subclass")}
      followed by plot(m.out).}
    \label{diagqqsub}
  \end{center}
\end{figure}

\begin{figure}[tbp]
  \begin{center}
<<fig=TRUE, width=8, height=5, prefix.string=figs/docs, echo=FALSE>>=
plot(m.out, type="jitter", interactive=FALSE)
@
    %\includegraphics[scale=0.5]{figs/jitterplotsub}
    \hfill
    \caption{Sample diagnostic jitter plot: Subclassification with
      \MatchIt\ call \texttt{matchit(treat ~ re74 + re75 + educ +
        black + hispan + age, data = lalonde, method = "subclass")
        followed by plot(m.out, type="jitter")}.  Vertical lines
      indicate the subclass cut points and the area of each diamond is
      proportional to the weights of the matched units for each
      subclass.  Unmatched units would be shown in grey.}
    \label{diagjittersub}
  \end{center}
\end{figure}

In Figure \ref{diagqqsub} we see that the empirical distributions of
the treated and control units are much more similar in Subclass 3
(shown in the ``Matched'' column of figures) than they are in the full
data set (shown in the ``Raw'' column of figures).  We see that in
this case, the distributions of most of the covariates are very
similar in Subclass 3, with the exception of \texttt{age}, on
which the treated units generally have larger values than the control
units (indicated by the points falling above the 45 degree line).  The
jitter plot indicates that using the \texttt{discard} option may be
desirable here, to reduce any bias due to the many control units with
low propensity scores.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Conducting Analyses after Matching}
\label{subsec:analysis}

\input{matchit2zelig}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Reference Manual}
\label{sec:reference}

\subsection{Inputs}
\label{subsec:inputs}

\input{matchitinputs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Outputs}
\label{subsec:outputs}

\subsubsection{Output Object Contents}

\input{matchitoutputs}

\subsubsection{{\tt summary()}}
The \texttt{summary()} command returns more information about the
\MatchIt\ model.  Optional inputs are:

\begin{enumerate}
\item \texttt{interactions}, which is an option to calculate summary
  statistics in \texttt{sum.all} and \texttt{sum.matched} for all
  covariates, their squares, and two-way interactions when
  \texttt{interactions = TRUE} and only the covariates themselves when
  \texttt{interactions = FALSE} (default).
\item \texttt{addlvariables}, which may contain additional variables
  on which to calculate the diagnostic statistics (in addition to the
  variables included in the matching procedure).  By default,
  \texttt{addlvariables = NULL}.  \texttt{addlvariables} must be
  specified as a data frame, with the same number of units and units
  in the same order as in the data set sent to \MatchIt .
\end{enumerate}

The output from the \texttt{summary()} command includes the following
elements, when applicable:
\begin{enumerate}
\item The original assignment model call.
\item \texttt{sum.all} is a data frame that contains variable names
  and interactions down the row names, and summary statistics on
  \emph{all observations} in each of the columns.  The columns in
  \texttt{sum.all} contain \footnote{The output for full matching is
    slightly different from that described here; see Section
    \ref{subsubsec:full} for details.}:
  \begin{itemize}
  \item means of all covariates $X$ for treated and control units,
    where \texttt{Means Treated}$= \mu_{X|T=1} = \frac{1}{n_1}
    \sum_{T=1} X_i$ and \texttt{Means Control}$= \mu_{X|T=0} =
    \frac{1}{n_0} \sum_{T=0} X_i$,
  \item standard deviation in the treated group for all covariates $X$,  
        $\quad s_{x|T=1} = \sqrt{\frac{\sum_{i \in \{i: T_i=1\}}
        X_i - \mu_{X|T=1}}{n_1-1} }.$
  \item summary statistics from a Q-Q plot, which compares treated and
    control covariate distributions, where \texttt{QQ Med}, \texttt{QQ
      Mean}, and \texttt{QQ Max} indicate the median, mean, and
    maximum orthogonal deviations from the 45 degree line of a Q-Q
    plot.
  \item standardized bias statistics, $${\rm Std.
      Bias}=\frac{\mu_{X|T=1} - \mu_{X|T=0}}{s_{x|T=1}}.$$
  \end{itemize}
  
\item \texttt{sum.matched} is a data frame which contains variable
  names down the row names, and summary statistics on only the
  \emph{matched observations} in each of the columns.  Specifically,
  the columns in \texttt{sum.matched} contain the following
  elements\footnote{The values output for full matching are slightly
    different from that described here; see Section \ref{subsubsec:full}
    for details}:
  \begin{itemize}
  \item weighted means for matched treatment units of all covariates
    $X$ and their interactions, where \texttt{Means Treated}$=
    \mu_{wX|T=1} = \frac{1}{n_1} \sum_{T=1} w_iX_i$ and \texttt{Means
      Control}$=\mu_{wX|T=0} = \frac{1}{n_0} \sum_{T=0} w_iX_i$,
  \item weighted standard deviations in the matched treated group 
   for all covariates $X$, where \texttt{SD} $= 
    s_{wX} =
    \sqrt{\frac{1}{n} \sum_{i} (w_iX_i - \overline{X}^*)^2}$, where
    $\overline{X}^*$ is the weighted mean of $X$ in the matched treated group.
  \item standardized bias statistics \texttt{Std.
      Bias}$=\frac{\mu_{wX|T=1} - \mu_{wX|T=0}}{s_{x|T=1}}$, and
  \end{itemize}
  where $w$ represents the vector of \texttt{weights}.
  
\item \texttt{reduction} shows the percent bias reduction achieved in
  each of the balance measures in \texttt{sum.all} and
  \texttt{sum.matched}, defined as $100(|a|-|b|)/|a|$, where $a$ was
  the value of the balance measure before matching and $b$ is the
  value of the balance measure after matching.  Because the difference
  in means and the standardized bias differ only by a constant (the
  standard deviation in the full treated group), the percent reduction
  in bias is the same for these two measures, and thus is only printed
  out once.

\item \texttt{nn} gives the sample sizes in the full and matched
  samples and the number of discarded units, by treatment and control.
  
\item \texttt{q.table} is an array that contains the same information
  as \texttt{sum.matched} by subclass.
  
\item \texttt{qn} gives the sample sizes in the full and matched
  samples and the number of discarded units, by subclass and by
  treatment and control.
\item \texttt{match.matrix} from the {\texttt matchit} output.
\end{enumerate}

\subsubsection{{\tt plot()}}

The \texttt{plot()} command allows you to check the distributions of
covariates in the assignment model, squares, and interactions, and
within each subclasses if specified.  The graphs present:
\begin{enumerate}
\item Q-Q plots of each covariate to check balance of marginal
  distributions (\texttt{type = "QQ"} (default)).  This graph plots
  covariate values that fall in (approximately) the same quantile of
  treated and control distributions.  Control unit quantile values are
  plotted on the x-axis, and treated unit quantile values are plotted
  on the y-axis.  If values fall below the 45 degree line, control
  units generally take lower values of the covariate.  Data points
  that fall exactly on the 45 degree line indicate that the marginal
  distributions are identical.  Discrete covariates that take 5 or
  fewer values are jittered for visibility.  This may be changed by
  setting the option \texttt{discrete.cutoff}.  Since there can be
  many covariates (and many subclasses in subclassification), the
  default Q-Q plot is interactive.  That is, after plotting a $3
  \times 2$ panel of raw and matched Q-Q plots for three covariates,
  user input is required to plot the next panel, if necessary.
  Similarly, user input is required when plotting by subclass.  This
  interactivity can be turned off by setting the input
  \texttt{interactive = F}. When subclassifying, users can then
  specify the subclass by the \texttt{subclass} input.
\item Jitter plots of the propensity score for treated and control
  units (\texttt{type = "jitter"}).  If \texttt{interactive=TRUE} (the default), the 
  user can identify individual units by clicking on the graph with the left mouse button.  
\end{enumerate}

\subsubsection{{\tt match.data()}}
\label{subsec:match.data}

To extract the matched data set for subsequent analyses from the
output object (see Section~\ref{subsec:analysis}), we provide the
function {\tt match.data()}.  This is used as follows:
<<results=hide, eval=FALSE>>=
m.data <- match.data(object, group = "all", distance = "distance", weights = "weights", subclass = "subclass")
@
The output of the function {\tt match.data()} is the original data
frame where additional information about matching (i.e., distance
measure as well as resulting weights and subclasses) is added,
restricted to units that were matched.

\paragraph{Inputs}

{\tt match.data()} takes the following inputs:
\begin{enumerate}
\item {\tt object} is the output object from {\tt matchit()}. This is
  a required input.
\item {\tt group} specifies for which matched group the user wants to
  extract the data. Available options are {\tt "all"} (all matched
  units), {\tt "treat"} (matched units in the treatment group), and
  {\tt "control"} (matched units in the control group). The default is
  {\tt "all"}.
\item {\tt distance} specifies the variable name used to store the
  distance measure. The default is {\tt "distance"}.
\item {\tt weights} specifies the variable name used to store the
  resulting weights from matching. The default is {\tt "weights"}. See
  Section~\ref{subsec:weights} for more details on the weights.
\item {\tt subclass} specifies the variable name used to store the
  subclass indicator. The default is {\tt "subclass"}.
\end{enumerate}

\paragraph{Examples}

Here, we present examples for using {\tt match.data()}. Users can run
these commands by typing {\tt demo(match.data)} at the R
prompt. First, we load the Lalonde data,
<<results=hide>>=
data(lalonde)
@
The next line performs nearest neighbor matching based on the
estimated propensity score from the logistic regression,
<<results=hide>>=
m.out1 <- matchit(treat ~ re74 + re75 + age + educ, data = lalonde, method = "nearest", distance = "logit")
@
To obtain matched data, type the following command, 
<<results=hide>>=
m.data1 <- match.data(m.out1)
@
It is easy to summarize the resulting matched data,
<<results=hide>>=
summary(m.data1)
@
To obtain matched data for the treatment or control group, specify the option
{\tt group} as follows,
<<results=hide>>=
m.data2 <- match.data(m.out1, group = "treat")
summary(m.data2)
m.data3 <- match.data(m.out1, group = "control")
summary(m.data3)
@
We can also specify different names for the subclass indicator, the
weight variable, and the estimated distance measure. The following
example first does a subclassification method, obtains the
matched data with specified names for those three variables, and then
print out the names of all variables in the resulting matched data.
<<results=hide>>=
m.out2 <- matchit(treat ~ re74 + re75 + age + educ, data=lalonde, method = "subclass")
m.data4 <- match.data(m.out2, subclass = "block", weights = "w", distance = "pscore")
names(m.data4)
@


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{What's New?}

\begin{itemize}
\item \textbf{2.1-1} (September 16, 2005): Stable release for R
  	2.1. Genetic matching added.	
\item \textbf{2.0-1} (August 29, 2005): Stable release for R 2.1.
  Major revisions including some syntax changes. Statistical tests are
  no longer used for balance checking, which are now based on the
  empirical covariate distributions (e.g., quantile-quantile plot).
\item \textbf{1.0-2} (August 10, 2005): Stable release for R
  2.1. Minor bug fixes (Thanks to Bart Bonikowski).
\item \textbf{1.0-1} (January 3, 2005): Stable release for R 2.0. The
  first official version of \MatchIt
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Frequently Asked Questions}

%\subsection{Can I use a Difference-in-Difference Estimator for Matched
%  Data?}
%
%A difference-in-differences (DID) analysis can be easily conducted
%with \MatchIt.  If we were interested in the DID matching estimate in
%the Lalonde data, we could simply include {\texttt re75} as a
%covariate in the preprocessing step.  Then the analysis can be
%performed on the change in income from 1975 to 1978: {\tt re78}-{\tt
%  re75}.  Time-varying covariates (of which none exist in the Lalonde
%data) should of course also be differenced for the DID estimator.
%** we should show how to do this with zelig

\subsection{How Exactly are the Weights Created?}
\label{subsec:weights}

Each type of matching method can be thought of as creating groups of
units with at least one treated unit and at least one control unit in
each.  In exact matching, subclassification, or full matching, these
groups are the subclasses formed, and the number of treated and
control units will vary quite a bit across subclasses.  In nearest
neighbor or optimal matching, the groups are the pairs (or sets) of
treated and control units matched.  In 1:1 nearest neighbor matching
there will be one treated unit and one control unit in each group.  In
2:1 nearest neighbor matching there will be one treated unit and two
control units in each group.  Unmatched units receive a weight of 0.
All matched treated units receive a weight of 1.

The weights for matched control units are formed as follows:
\begin{enumerate}
\item Within each group, each control unit is given a preliminary
  weight of $n_{ti}/n_{ci}$, where $n_{ti}$ and $n_{ci}$ are the
  number of treated and control units in group $i$, respectively.
\item If matching is done with replacement, each control unit's weight
  is added up across the groups in which it was matched.
\item The control group weights are scaled to sum to the number of
  uniquely matched control units.
\end{enumerate}

With subclassification, when the analysis is done separately within
each subclass and then aggregated up across the subclasses, these
weights will generally not be used, but they may be used for full
matching or nearest neighbor matching if the number of control units
matched to each treated unit varies.

\subsection{How Do I Create Observation Names?}
\label{rnames}

Since the diagnostics often make use of the observation names of the
data frame, you may find it helpful to specify observation names for
the data input.  Use the \texttt{row.names} command to achieve this.
For example, to assign the names ``Dan'', ``Kosuke'', ``Liz'' and
``Gary'' to a data frame with the first four observations in the
Lalonde data, type:

<<>>=
test <- lalonde[1:4,]  #taking a lalonde subset
row.names(test) <- c("Dan","Kosuke","Liz","Gary")  #assigning row names
print(test)
@

\subsection{How Do I Ensure Replicability As \MatchIt\ Versions Develop?}
\label{subsec:vercontrol}
As the literature on matching techniques is rapidly evolving,
\MatchIt\ will strive to incorporate new developments. \MatchIt\ is
thereby an evolving program.  Users may be concerned that analysis
written in a particular version may not be compatible with newer
versions of the program.  The primary way to ensure that replication
archives remain valid is to record the version of \MatchIt\ that was
used in the analysis.  Our website maintains binaries of all public
release versions, so that researchers can replicate results exactly
with the appropriate version (for Unix-based platforms, see
\hlink{http://gking.harvard.edu/src/contrib/}{http://gking.harvard.edu/src/contrib/};
for windows, see
\hlink{http://gking.harvard.edu/bin/windows/contrib/}{http://gking.harvard.edu/bin/windows/contrib/}).

In addition, users may find it helpful to install packages with
version control, using the {\tt installWithVers} command with {\tt
install.packages}.  So for example, in the windows R console, users
may download the appropriate version from our website and install the
package with version control by:

\begin{verbatim}
install.packages(choose.files('',filters=Filters[c('zip','All'),]),
                 .libPaths()[1],installWithVers=T,CRAN=NULL)
\end{verbatim}

R CMD INSTALL similarly permits users to specify this version using
the {\tt --with-package-versions} option.  After having specified
version control, different versions of the program may be called as
necessary.  Similar advice may also be appropriate for version control
for R more generally.

\subsection{What Do I Do about Missing Data?}

\MatchIt\ requires complete data sets, with no missing values (other
than potential outcomes of course).  If there are missing values in
the data set, imputation techniques should be used first to fill in
(``impute'') the missing values (both covariates and outcomes), or the
analysis should be done using only complete cases (which we do not in
general recommend).  For imputation software, see Amelia at
(\hlink{http://gking.harvard.edu/stats.shtml}{http://gking.harvard.edu/stats.shtml})
or other programs at
\hlink{http://www.multiple-imputation.com}{http://www.multiple-imputation.com}.
For more information on missing data and imputation methods, see
\cite{KinHonJos01}.

\subsection{Why Preprocessing?}

The purpose of matching is to approximate an experimental template,
where the matching procedure approximates random assignment of
treatment in order to balance covariates between treatment and control
groups.  Separation of the estimation procedure into two steps
simulates the research design of an experiment, where no information
on outcomes is known at the point of experimental design and
randomization.  Much like an experimenter cannot easily rerun an
experiment if the outcome was not satisfactory, the separation of the
balancing process in \MatchIt\ from the analysis process afterward
helps keep clear the goal of balancing control and treatment groups
and makes it less likely that the user will inadvertently cook the
books in his or her favor.

\clearpage
\bibliographystyle{polisci}
\bibliography{gk,gkpubs}

\end{document}

